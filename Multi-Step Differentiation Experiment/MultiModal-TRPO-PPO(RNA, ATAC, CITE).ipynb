{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81945e89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ File filtered_feature_bc_matrix.h5 from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/filtered_feature_bc_matrix.h5\n",
      "■ Checksum is validated (md5) for filtered_feature_bc_matrix.h5\n",
      "■ File atac_fragments.tsv.gz from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_fragments.tsv.gz\n",
      "■ Checksum is validated (md5) for atac_fragments.tsv.gz\n",
      "■ File atac_fragments.tsv.gz.tbi from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_fragments.tsv.gz.tbi\n",
      "■ Checksum is validated (md5) for atac_fragments.tsv.gz.tbi\n",
      "■ File atac_peaks.bed from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_peaks.bed\n",
      "■ Checksum is validated (md5) for atac_peaks.bed\n",
      "■ File atac_peak_annotation.tsv from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_peak_annotation.tsv\n",
      "■ Checksum is validated (md5) for atac_peak_annotation.tsv\n",
      "■ Loading filtered_feature_bc_matrix.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudatasets/core.py:203: UserWarning: Dataset is in the 10X .h5 format and can't be loaded as backed.\n",
      "  warn(\"Dataset is in the 10X .h5 format and can't be loaded as backed.\")\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/anndata/_core/anndata.py:1776: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added `interval` annotation for features from /Users/boabangfrancis/mudatasets/pbmc10k_multiome/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/anndata/_core/anndata.py:1776: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudata/_core/mudata.py:1598: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"var\", axis=0, join_common=join_common)\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudata/_core/mudata.py:947: UserWarning: var_names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  warnings.warn(\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudata/_core/mudata.py:1461: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"obs\", axis=1, join_common=join_common)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added peak annotation from /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_peak_annotation.tsv to .uns['atac']['peak_annotation']\n",
      "Added gene names to peak annotation in .uns['atac']['peak_annotation']\n",
      "Located fragments file: /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_fragments.tsv.gz\n",
      "pysam is not available. It is required to work with the fragments file.                 Install pysam from PyPI (`pip install pysam`)                 or from GitHub (`pip install git+https://github.com/pysam-developers/pysam`)\n",
      "Available modalities: ['rna', 'atac']\n",
      "Number of common cells: 10000\n",
      "{'rna': (10000, 32), 'atac': (10000, 32)}\n",
      "Modality splits: {'rna': (0, 32), 'atac': (32, 64)}\n",
      "\n",
      "===== Training TRPO =====\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 4341 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                     |          |\n",
      "|    fps                    | 3198     |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 1        |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | -0.00201 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00406  |\n",
      "|    learning_rate          | 0.0001   |\n",
      "|    n_updates              | 1        |\n",
      "|    policy_objective       | 7.5e+06  |\n",
      "|    std                    | 1        |\n",
      "|    value_loss             | 39.1     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                     |          |\n",
      "|    fps                    | 2948     |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 2        |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.00146  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00339  |\n",
      "|    learning_rate          | 0.0001   |\n",
      "|    n_updates              | 2        |\n",
      "|    policy_objective       | 2.74e+07 |\n",
      "|    std                    | 1        |\n",
      "|    value_loss             | 54.3     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                     |          |\n",
      "|    fps                    | 2832     |\n",
      "|    iterations             | 4        |\n",
      "|    time_elapsed           | 2        |\n",
      "|    total_timesteps        | 8192     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | -0.0034  |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00279  |\n",
      "|    learning_rate          | 0.0001   |\n",
      "|    n_updates              | 3        |\n",
      "|    policy_objective       | 3.41e+05 |\n",
      "|    std                    | 1        |\n",
      "|    value_loss             | 39.7     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                     |          |\n",
      "|    fps                    | 2777     |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 3        |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.024    |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00267  |\n",
      "|    learning_rate          | 0.0001   |\n",
      "|    n_updates              | 4        |\n",
      "|    policy_objective       | 2.06e+03 |\n",
      "|    std                    | 1        |\n",
      "|    value_loss             | 37.6     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                     |          |\n",
      "|    fps                    | 2743     |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 4        |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.0193   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00283  |\n",
      "|    learning_rate          | 0.0001   |\n",
      "|    n_updates              | 5        |\n",
      "|    policy_objective       | 1.71e+03 |\n",
      "|    std                    | 0.999    |\n",
      "|    value_loss             | 62       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                     |          |\n",
      "|    fps                    | 2715     |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 5        |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.0158   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00273  |\n",
      "|    learning_rate          | 0.0001   |\n",
      "|    n_updates              | 6        |\n",
      "|    policy_objective       | 2.57e+04 |\n",
      "|    std                    | 0.999    |\n",
      "|    value_loss             | 34.7     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                     |          |\n",
      "|    fps                    | 2694     |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 6        |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 0.0652   |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00238  |\n",
      "|    learning_rate          | 0.0001   |\n",
      "|    n_updates              | 7        |\n",
      "|    policy_objective       | 6.44e+05 |\n",
      "|    std                    | 1        |\n",
      "|    value_loss             | 49.8     |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from scipy.sparse import csr_matrix\n",
    "import muon as mu\n",
    "from sb3_contrib.trpo import TRPO\n",
    "import mudatasets as mds\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility & device\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "MAX_STEPS = 200\n",
    "PERTURB_PROB = 0.8\n",
    "MAX_PERTURB = 40\n",
    "N_EVAL_EPISODES = 30\n",
    "#OUT_DIR = \"pbmc_multi_output\"\n",
    "PLOTS_DIR = os.path.join(OUT_DIR, \"pseudotime_plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Load PBMC multiome dataset\n",
    "# -----------------------------\n",
    "mdata = mds.load(\"pbmc10k_multiome\", full=True)\n",
    "mdata.var_names_make_unique()\n",
    "print(\"Available modalities:\", list(mdata.mod.keys()))\n",
    "\n",
    "# -----------------------------\n",
    "# Subset cells for speed\n",
    "# -----------------------------\n",
    "subset_cells = np.random.choice(mdata.mod['rna'].obs_names, size=10000, replace=False)\n",
    "rna = mdata.mod['rna'][subset_cells].copy()\n",
    "atac = mdata.mod['atac'][subset_cells].copy()\n",
    "adt = mdata.mod['adt'][subset_cells].copy() if 'adt' in mdata.mod else None\n",
    "\n",
    "# -----------------------------\n",
    "# Common cells across modalities\n",
    "# -----------------------------\n",
    "common_cells = rna.obs_names.intersection(atac.obs_names)\n",
    "if adt is not None:\n",
    "    common_cells = common_cells.intersection(adt.obs_names)\n",
    "common_cells = np.array(common_cells)\n",
    "print(\"Number of common cells:\", len(common_cells))\n",
    "\n",
    "# -----------------------------\n",
    "# Sparse matrices\n",
    "# -----------------------------\n",
    "rna_X = csr_matrix(rna.X)\n",
    "atac_X = csr_matrix(atac.X)\n",
    "adt_X = csr_matrix(adt.X) if adt is not None else None\n",
    "\n",
    "# -----------------------------\n",
    "# Simple GAT Encoder\n",
    "# -----------------------------\n",
    "class SimpleGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=64, out_dim=32, heads=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_dim, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_dim*heads, out_dim, heads=1, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# -----------------------------\n",
    "# kNN Graph Helper\n",
    "# -----------------------------\n",
    "def compute_knn_graph(X, k=5):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, metric='cosine').fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    edge_index = []\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in indices[i]:\n",
    "            if i != j:\n",
    "                edge_index.append([i, j])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "# -----------------------------\n",
    "# GAT embedding function\n",
    "# -----------------------------\n",
    "def gat_embedding(X_np):\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "    edge_index = compute_knn_graph(X_np, k=3)\n",
    "    model = SimpleGAT(in_dim=X.shape[1])\n",
    "    with torch.no_grad():\n",
    "        Z = model(X, edge_index)\n",
    "    return Z.numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# Compute embeddings per modality\n",
    "# -----------------------------\n",
    "z_rna = gat_embedding(rna_X.toarray())\n",
    "z_atac = gat_embedding(atac_X.toarray())\n",
    "z_adt = gat_embedding(adt_X.toarray()) if adt is not None else None\n",
    "\n",
    "modality_data = {'rna': z_rna, 'atac': z_atac}\n",
    "if adt is not None:\n",
    "    modality_data['adt'] = z_adt\n",
    "print({k:v.shape for k,v in modality_data.items()})\n",
    "\n",
    "# -----------------------------\n",
    "# Scale & train/test split\n",
    "# -----------------------------\n",
    "expression_train, expression_test = {}, {}\n",
    "pseudotime_train, pseudotime_test = {}, {}\n",
    "scalers = {}\n",
    "\n",
    "for mod, data in modality_data.items():\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    scalers[mod] = scaler\n",
    "    train_idx, test_idx = train_test_split(np.arange(data_scaled.shape[0]), test_size=0.2, random_state=SEED)\n",
    "    expression_train[mod] = data_scaled[train_idx]\n",
    "    expression_test[mod] = data_scaled[test_idx]\n",
    "    pseudotime = np.arange(data_scaled.shape[0], dtype=np.float32)\n",
    "    pseudotime_train[mod] = pseudotime[train_idx]\n",
    "    pseudotime_test[mod] = pseudotime[test_idx]\n",
    "\n",
    "# -----------------------------\n",
    "# Fuse modalities\n",
    "# -----------------------------\n",
    "fused_train = np.concatenate([expression_train[m] for m in expression_train.keys()], axis=1)\n",
    "fused_test = np.concatenate([expression_test[m] for m in expression_test.keys()], axis=1)\n",
    "\n",
    "modality_dims = {mod: expression_train[mod].shape[1] for mod in expression_train.keys()}\n",
    "starts = np.cumsum([0] + list(modality_dims.values()))[:-1]\n",
    "modality_splits = {}\n",
    "idx = 0\n",
    "for mod, dim in modality_dims.items():\n",
    "    start = idx\n",
    "    end = idx + dim\n",
    "    modality_splits[mod] = (start, end)\n",
    "    idx = end\n",
    "total_features = fused_train.shape[1]\n",
    "selected_gene_names = [f\"feat_{i}\" for i in range(total_features)]\n",
    "print(\"Modality splits:\", modality_splits)\n",
    "\n",
    "# -----------------------------\n",
    "# Gene names per modality\n",
    "# -----------------------------\n",
    "gene_name_mod = {}\n",
    "for mod, (start, end) in modality_splits.items():\n",
    "    gene_name_mod[mod] = [f\"{mod}_{i}\" for i in range(end-start)]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class PerGeneAdaptiveThreshold:\n",
    "    def __init__(self, modality_dims, alpha=0.1):\n",
    "        self.thresholds = {mod: {i: 0.0 for i in range(dim)} for mod, dim in modality_dims.items()}\n",
    "        self.alpha = alpha\n",
    "    def update(self, gene_rewards):\n",
    "        for mod, rewards in gene_rewards.items():\n",
    "            for gene_id, reward in rewards.items():\n",
    "                if reward is None or (isinstance(reward, float) and np.isnan(reward)):\n",
    "                    continue\n",
    "                self.thresholds[mod][gene_id] = self.alpha*float(reward) + (1-self.alpha)*self.thresholds[mod].get(gene_id,0.0)\n",
    "    def get(self, mod, gene_id):\n",
    "        return float(self.thresholds.get(mod, {}).get(gene_id,0.0))\n",
    "\n",
    "adaptive_thresholds = PerGeneAdaptiveThreshold(modality_dims)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# -----------------------------\n",
    "# Evaluate & plot per-gene/per-modality\n",
    "# -----------------------------\n",
    "def evaluate_and_plot_multi_modality(model, algo_name, expression_test, pseudotime_test,\n",
    "                                     gene_names, modality_splits, adaptive_thresholds=None,\n",
    "                                     n_episodes=N_EVAL_EPISODES, save_dir=PLOTS_DIR):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    for mod_name, (start_idx, end_idx) in modality_splits.items():\n",
    "        print(f\"Evaluating modality: {mod_name} (genes {start_idx}:{end_idx})\")\n",
    "        gene_names = gene_name_mod.get(mod_name, [f\"g{i}\" for i in range(end_idx - start_idx)])\n",
    "\n",
    "        for gene_idx in range(start_idx, end_idx):\n",
    "            gene_name = gene_names[gene_idx - start_idx]\n",
    "\n",
    "            y_true, y_pred = [], []\n",
    "            perturbed_vals, original_vals, pseudotimes = [], [], []\n",
    "\n",
    "            for ep in range(n_episodes):\n",
    "                obs = expression_test[ep % expression_test.shape[0]]  # sample a cell\n",
    "                true_expr = obs[gene_idx]                            # true expression for this gene\n",
    "\n",
    "                # RL model prediction\n",
    "                action, _ = model.predict(obs, deterministic=True)\n",
    "                pred_expr = np.clip(obs[gene_idx] + action[gene_idx], -5, 5)\n",
    "\n",
    "                y_true.append(1 if true_expr > 0 else 0)\n",
    "                y_pred.append(1 if pred_expr > 0 else 0)\n",
    "\n",
    "                original_vals.append(true_expr)\n",
    "                perturbed_vals.append(pred_expr)\n",
    "                pseudotimes.append(pseudotime_test[ep % len(pseudotime_test)])\n",
    "\n",
    "            # --- compute metrics properly ---\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            try:\n",
    "                auprc = average_precision_score(y_true, y_pred)\n",
    "            except Exception:\n",
    "                auprc = np.nan\n",
    "            mse = mean_squared_error(original_vals, perturbed_vals)\n",
    "            rmse = math.sqrt(mse)\n",
    "            mae = mean_absolute_error(original_vals, perturbed_vals)\n",
    "            r2 = r2_score(original_vals, perturbed_vals)\n",
    "            pc = np.corrcoef(original_vals, perturbed_vals)[0, 1] if np.std(original_vals) != 0 else 0.0\n",
    "\n",
    "            results.append({\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Modality\": mod_name,\n",
    "                \"Gene\": gene_name,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1\": f1,\n",
    "                \"AUPRC\": auprc,\n",
    "                \"Final Expression MSE\": mse,\n",
    "                \"Final Expression RMSE\": rmse,\n",
    "                \"Final Expression MAE\": mae,\n",
    "                \"Final Expression R²\": r2,\n",
    "                \"Final Expression PearsonCorr\": pc\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "# df_metrics = evaluate_and_plot_multi_modality(\n",
    "#     model=None,\n",
    "#     algo_name=\"PPO\",\n",
    "#     expression_test=fused_test,\n",
    "#     pseudotime_test=pseudotime_test,\n",
    "#     gene_name_mod=gene_name_mod,\n",
    "#     modality_splits=modality_splits\n",
    "# )\n",
    "# print(df_metrics.head())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Scale & train/test split for each modality\n",
    "# -----------------------------\n",
    "\n",
    "def scale_and_split(modality_data, test_size=0.2, seed=SEED):\n",
    "    expression_train, expression_test = {}, {}\n",
    "    pseudotime_train, pseudotime_test = {}, {}\n",
    "    scalers = {}\n",
    "\n",
    "    for mod, data in modality_data.items():\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "        scalers[mod] = scaler\n",
    "        train_idx, test_idx = train_test_split(np.arange(data_scaled.shape[0]), test_size=test_size, random_state=seed)\n",
    "        expression_train[mod] = data_scaled[train_idx]\n",
    "        expression_test[mod] = data_scaled[test_idx]\n",
    "        pseudotime = np.arange(data_scaled.shape[0], dtype=np.float32)\n",
    "        pseudotime_train[mod] = pseudotime[train_idx]\n",
    "        pseudotime_test[mod] = pseudotime[test_idx]\n",
    "\n",
    "    return expression_train, expression_test, pseudotime_train, pseudotime_test, scalers\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Adaptive per-gene thresholds (simple moving average)\n",
    "# -----------------------------\n",
    "class PerGeneAdaptiveThreshold:\n",
    "    def __init__(self, modality_dims, alpha=0.1):\n",
    "        # modality_dims: dict mod -> int (number of features)\n",
    "        self.thresholds = {mod: {i: 0.0 for i in range(dim)} for mod, dim in modality_dims.items()}\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, gene_rewards):\n",
    "        for mod, rewards in gene_rewards.items():\n",
    "            for gene_id, reward in rewards.items():\n",
    "                if reward is None or (isinstance(reward, float) and np.isnan(reward)):\n",
    "                    continue\n",
    "                self.thresholds[mod][gene_id] = self.alpha * float(reward) + (1 - self.alpha) * self.thresholds[mod].get(gene_id, 0.0)\n",
    "\n",
    "    def get(self, mod, gene_id):\n",
    "        return float(self.thresholds.get(mod, {}).get(gene_id, 0.0))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# PBMC_CRISPR_MultiModalEnv (Gym)\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ... other imports and class definitions ...\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class PBMC_CRISPR_MultiModalEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, expression_dict_or_matrix, pseudotime_dict_or_array, modality_splits,\n",
    "                 max_steps=MAX_STEPS, adaptive_thresholds=None, device='cpu',\n",
    "                 action_magnitude=0.25, perturb_prob=0.1, max_perturb=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Accept either dicts (per-modality) or already-fused matrices\n",
    "        if isinstance(expression_dict_or_matrix, dict):\n",
    "            # build fused matrix in modality_splits order\n",
    "            self.expression_dict = {mod: np.asarray(expression_dict_or_matrix[mod], dtype=np.float32) for mod in modality_splits.keys()}\n",
    "            self.expression = np.concatenate([self.expression_dict[mod] for mod in modality_splits.keys()], axis=1)\n",
    "            # pseudotime: use first modality's pseudotime (cell-level)\n",
    "            self.pseudotime = np.asarray(next(iter(pseudotime_dict_or_array.values())), dtype=np.float32)\n",
    "        else:\n",
    "            self.expression = np.asarray(expression_dict_or_matrix, dtype=np.float32)\n",
    "            self.expression_dict = {}\n",
    "            start = 0\n",
    "            for mod, (s, e) in modality_splits.items():\n",
    "                self.expression_dict[mod] = self.expression[:, s:e]\n",
    "            self.pseudotime = np.asarray(pseudotime_dict_or_array, dtype=np.float32)\n",
    "\n",
    "        self.modality_splits = modality_splits\n",
    "        self.modality_dims = {m: (e - s) for m, (s, e) in modality_splits.items()}\n",
    "        self.n_cells, self.n_genes = self.expression.shape\n",
    "        self.max_steps = max_steps\n",
    "        self.adaptive_thresholds = adaptive_thresholds\n",
    "        self.device = device\n",
    "        self.action_magnitude = action_magnitude\n",
    "        self.perturb_prob = perturb_prob\n",
    "        self.max_perturb = max_perturb\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(self.n_genes,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_genes,), dtype=np.float32)\n",
    "\n",
    "        # bookkeeping\n",
    "        self.current_cell = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.idx = np.random.randint(self.n_cells)\n",
    "        self.state = self.expression[self.idx].copy()\n",
    "        self.original_state = self.state.copy()\n",
    "\n",
    "        eligible_idxs = np.where(np.arange(self.n_cells) > self.idx)[0]\n",
    "        if len(eligible_idxs) == 0:\n",
    "            eligible_idxs = np.array([self.idx])\n",
    "        target_idx = np.random.choice(eligible_idxs)\n",
    "        self.target = self.expression[target_idx].copy()\n",
    "\n",
    "        self.steps = 0\n",
    "        self.history = [self.state.copy()]\n",
    "        self.knockout_genes = set()\n",
    "        self.overexpressed_genes = set()\n",
    "        self._apply_crispr_perturbation()\n",
    "        self.current_cell = 0\n",
    "        return self.state.copy()\n",
    "\n",
    "    def _apply_crispr_perturbation(self):\n",
    "        n_perturb = np.random.randint(1, self.max_perturb + 1)\n",
    "        for _ in range(n_perturb):\n",
    "            gene = np.random.randint(0, self.n_genes)\n",
    "            if np.random.rand() < 0.5:\n",
    "                self.state[gene] = 0.0\n",
    "                self.knockout_genes.add(int(gene))\n",
    "            else:\n",
    "                self.state[gene] = self.state[gene] * 2.0\n",
    "                self.overexpressed_genes.add(int(gene))\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.asarray(action, dtype=np.float32).ravel()\n",
    "        if action.shape[0] != self.n_genes:\n",
    "            raise ValueError(\"Action length mismatch.\")\n",
    "        for i, delta in enumerate(action):\n",
    "            self.state[i] = np.clip(self.state[i] + delta * self.action_magnitude, -5.0, 5.0)\n",
    "\n",
    "        if np.random.rand() < self.perturb_prob:\n",
    "            self._apply_crispr_perturbation()\n",
    "\n",
    "        old_mse = float(np.mean((self.history[-1] - self.target) ** 2))\n",
    "        new_mse = float(np.mean((self.state - self.target) ** 2))\n",
    "        reward = old_mse - new_mse\n",
    "\n",
    "        # subtract adaptive thresholds per modality (if provided)\n",
    "        if self.adaptive_thresholds is not None:\n",
    "            for mod, (start, end) in self.modality_splits.items():\n",
    "                for local_idx, g in enumerate(range(start, end)):\n",
    "                    reward -= self.adaptive_thresholds.get(mod, local_idx)\n",
    "\n",
    "        self.steps += 1\n",
    "        self.history.append(self.state.copy())\n",
    "        terminated = self.steps >= self.max_steps\n",
    "        done = terminated\n",
    "        info = {}\n",
    "        self.current_cell += 1\n",
    "        return self.state.copy(), float(reward), done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Step {self.steps} - state (first 10): {self.state[:10]}\")\n",
    "        print(f\"Knockouts: {sorted(list(self.knockout_genes))[:10]}, Overexpr: {sorted(list(self.overexpressed_genes))[:10]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ... rest of the script ...\n",
    "# ... rest of the script ...\n",
    "# -----------------------------\n",
    "# SB3 wrapper (returns obs only on reset)\n",
    "# -----------------------------\n",
    "class GRNEnvWrapper(gym.Env):\n",
    "    def __init__(self, base_env):\n",
    "        super().__init__()\n",
    "        self.env = base_env\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.env.n_genes,), dtype=np.float32)\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        result = self.env.reset(**kwargs)\n",
    "        # gym may return obs or (obs, info)\n",
    "        if isinstance(result, tuple):\n",
    "            obs = result[0]\n",
    "        else:\n",
    "            obs = result\n",
    "        return np.asarray(obs, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        # handle both old and new gym API\n",
    "        if isinstance(result, tuple) and len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            done = bool(terminated or truncated)\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "        return np.asarray(obs, dtype=np.float32), float(reward), bool(done), info\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        if hasattr(self.env, 'seed'):\n",
    "            self.env.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# make_env_factory\n",
    "# -----------------------------\n",
    "def make_env_factory(expression, pseudotime, modality_splits, adaptive_thresholds, modality_choice=\"all\"):\n",
    "    def _init():\n",
    "        base_env = PBMC_CRISPR_MultiModalEnv(\n",
    "            expression_dict_or_matrix=expression,\n",
    "            pseudotime_dict_or_array=pseudotime,\n",
    "            modality_splits=modality_splits,\n",
    "            max_steps=MAX_STEPS,\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            device=DEVICE,\n",
    "            action_magnitude=0.25,\n",
    "            perturb_prob=PERTURB_PROB,\n",
    "            max_perturb=MAX_PERTURB\n",
    "        )\n",
    "        return GRNEnvWrapper(base_env)\n",
    "    return _init\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# evaluation helper for SB3 (mean/std reward)\n",
    "# -----------------------------\n",
    "def evaluate_model_sb3(model, env, n_eval_episodes=10, deterministic=True):\n",
    "    all_rewards = []\n",
    "    for episode in range(n_eval_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0.0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            if isinstance(reward, (list, tuple, np.ndarray)):\n",
    "                total_reward += float(np.mean(reward))\n",
    "            else:\n",
    "                total_reward += float(reward)\n",
    "        all_rewards.append(total_reward)\n",
    "    mean_reward = np.mean(all_rewards)\n",
    "    std_reward = np.std(all_rewards)\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Train & evaluate PPO / TRPO / TRPO->PPO\n",
    "# -----------------------------\n",
    "def train_and_evaluate_algorithms(modality_choice, expression_train, pseudotime_train,\n",
    "                                  expression_test, pseudotime_test, modality_splits,\n",
    "                                  gene_names, adaptive_thresholds,\n",
    "                                  algorithms_to_run=(\"ppo\", \"trpo\", \"trpo_to_ppo\"),\n",
    "                                  train_steps=100000, save_dir=OUT_DIR):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Environments\n",
    "    # -----------------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    # -----------------------------\n",
    "    # Modality-specific data\n",
    "    # -----------------------------\n",
    "    if modality_choice == \"all\":\n",
    "        expr_train_mod = expression_train\n",
    "        expr_test_mod = expression_test\n",
    "        pseudo_train_mod = pseudotime_train[next(iter(pseudotime_train.keys()))]  # pick any modality's pseudotime\n",
    "        pseudo_test_mod = pseudotime_test[next(iter(pseudotime_test.keys()))]\n",
    "        gene_names_mod = gene_names\n",
    "        splits_for_env_mod = modality_splits\n",
    "    else:\n",
    "        start, end = modality_splits[modality_choice]\n",
    "        expr_train_mod = expression_train[:, start:end]\n",
    "        expr_test_mod = expression_test[:, start:end]\n",
    "        pseudo_train_mod = pseudotime_train[modality_choice]\n",
    "        pseudo_test_mod = pseudotime_test[modality_choice]\n",
    "        splits_for_env_mod = {modality_choice: (0, end - start)}\n",
    "        gene_names_mod = [f\"{modality_choice}_{i}\" for i in range(end - start)]\n",
    "\n",
    "    train_env = DummyVecEnv([\n",
    "        make_env_factory(expr_train_mod, pseudo_train_mod, splits_for_env_mod, adaptive_thresholds, modality_choice)\n",
    "    ])\n",
    "   # train_env = VecNormalize(train_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
    "\n",
    "    eval_env = DummyVecEnv([\n",
    "        make_env_factory(expr_test_mod, pseudo_test_mod, splits_for_env_mod, adaptive_thresholds, modality_choice)\n",
    "    ])\n",
    "    eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
    "    \n",
    "    \n",
    "    trained_models = {}\n",
    "    results_reward = {}\n",
    "    test_metrics_df = []\n",
    "\n",
    "    # -----------------------------\n",
    "    # Algorithm-specific kwargs\n",
    "    # -----------------------------\n",
    "    ppo_kwargs = dict(\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=0.0,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        learning_rate=1e-4,\n",
    "        policy_kwargs=dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])], activation_fn=nn.Tanh)\n",
    "    )\n",
    "\n",
    "    trpo_kwargs = dict(\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        cg_max_steps=15,\n",
    "        cg_damping=0.01,\n",
    "        line_search_shrinking_factor=0.8,\n",
    "        n_critic_updates=10,\n",
    "        learning_rate=1e-4,\n",
    "        policy_kwargs=dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])], activation_fn=nn.Tanh)\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training Loop\n",
    "    # -----------------------------\n",
    "    for algo_name in algorithms_to_run:\n",
    "        print(f\"\\n===== Training {algo_name.upper()} =====\")\n",
    "\n",
    "        if algo_name == \"ppo\":\n",
    "            model = PPO(\"MlpPolicy\", train_env, verbose=1, seed=SEED, **ppo_kwargs)\n",
    "            model.learn(total_timesteps=train_steps)\n",
    "\n",
    "        elif algo_name == \"trpo\":\n",
    "            model = TRPO(\"MlpPolicy\", train_env, verbose=1, seed=SEED, **trpo_kwargs)\n",
    "            model.learn(total_timesteps=train_steps)\n",
    "\n",
    "        elif algo_name == \"trpo_to_ppo\":\n",
    "            # Stage 1: TRPO\n",
    "            model_trpo = TRPO(\"MlpPolicy\", train_env, verbose=1, seed=SEED, **trpo_kwargs)\n",
    "            model_trpo.learn(total_timesteps=max(1, 10000))\n",
    "\n",
    "            # Stage 2: PPO warm start\n",
    "            model = PPO(\"MlpPolicy\", train_env, verbose=1, seed=SEED, **ppo_kwargs)\n",
    "            try:\n",
    "                # try parameter transfer if shapes match\n",
    "                model.set_parameters(model_trpo.get_parameters())\n",
    "                print(\"✅ Parameters transferred from TRPO → PPO\")\n",
    "            except Exception as e:\n",
    "                print(\"⚠️ Parameter transfer failed, PPO starts fresh:\", e)\n",
    "            model.learn(total_timesteps=max(1, 100000-10000))\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠️ Unknown algorithm: {algo_name}\")\n",
    "            continue\n",
    "\n",
    "        # Save trained model\n",
    "        trained_models[algo_name] = model\n",
    "\n",
    "        # -----------------------------\n",
    "        # Evaluate\n",
    "        # -----------------------------\n",
    "        mean_r, std_r = evaluate_model_sb3(model, eval_env, n_eval_episodes=N_EVAL_EPISODES)\n",
    "        results_reward[algo_name] = (mean_r, std_r)\n",
    "        print(f\"✅ Eval {algo_name}: mean={mean_r:.4f}, std={std_r:.4f}\")\n",
    "\n",
    "        metrics_df = evaluate_and_plot_multi_modality(\n",
    "            model=model,\n",
    "            algo_name=algo_name,\n",
    "            expression_test=expr_test_mod,\n",
    "            pseudotime_test=pseudo_test_mod,\n",
    "            gene_names=gene_name_mod,\n",
    "            modality_splits=splits_for_env_mod,\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            n_episodes=N_EVAL_EPISODES,\n",
    "            save_dir=os.path.join(save_dir, \"plots\")\n",
    "        )\n",
    "        metrics_df.to_csv(os.path.join(save_dir, f\"{modality_choice}_{algo_name}_metrics.csv\"), index=False)\n",
    "        test_metrics_df.append(metrics_df)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save testing metrics\n",
    "    # -----------------------------\n",
    "    final_test_df = pd.concat(test_metrics_df, ignore_index=True)\n",
    "    final_test_df.to_csv(os.path.join(save_dir, f\"testing_per_gene_metrics_{modality_choice}.csv\"), index=False)\n",
    "    test_summary_df = final_test_df.groupby(\"Algorithm\").mean(numeric_only=True)\n",
    "    test_summary_df.to_csv(os.path.join(save_dir, f\"testing_overall_metrics_{modality_choice}.csv\"))\n",
    "\n",
    "    print(f\"\\n✅ Training & evaluation complete for all optimizers on modality={modality_choice}.\")\n",
    "\n",
    "\n",
    "    return trained_models, results_reward\n",
    "\n",
    "def evaluate_model_sb3(model, env, n_eval_episodes=10, deterministic=True):\n",
    "    \"\"\"\n",
    "    Evaluate a Stable-Baselines3 model.\n",
    "    \n",
    "    Returns:\n",
    "        mean_reward, std_reward\n",
    "    \"\"\"\n",
    "    all_rewards = []\n",
    "\n",
    "    for episode in range(n_eval_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0.0\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        all_rewards.append(total_reward)\n",
    "\n",
    "    mean_reward = np.mean(all_rewards)\n",
    "    std_reward = np.std(all_rewards)\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example run (change args as needed)\n",
    "# -----------------------------\n",
    "#\"pbmc_multi_output\"\n",
    "trained_models, results_reward = train_and_evaluate_algorithms(\n",
    "            modality_choice=\"atac\",\n",
    "            expression_train=fused_train,\n",
    "            pseudotime_train=pseudotime_train,\n",
    "            expression_test=fused_test,\n",
    "            pseudotime_test=pseudotime_test,\n",
    "            modality_splits=modality_splits,\n",
    "            gene_names=selected_gene_names,\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            algorithms_to_run=[\"trpo\", \"ppo\", \"trpo_to_ppo\"],\n",
    "            train_steps=100_000,\n",
    "            save_dir=\"pbmc_multi_output_atac\"\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56332a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce333680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec95c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8134c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb1b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
