{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6426e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muon as mu\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a422ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Full updated notebook cell: PBMC Multi-modal PPO with GAT embeddings\n",
    "# -----------------------------\n",
    "# Imports & settings\n",
    "# -----------------------------\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import muon as mu\n",
    "import mudatasets as mds\n",
    "import scanpy as sc\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# PyTorch Geometric for GAT embeddings\n",
    "# -----------------------------\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility & device\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MAX_STEPS = 100\n",
    "PERTURB_PROB = 0.5\n",
    "MAX_PERTURB = 40\n",
    "N_EVAL_EPISODES = 30\n",
    "OUT_DIR = \"pbmc_multi_output\"\n",
    "PLOTS_DIR = os.path.join(OUT_DIR, \"pseudotime_plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Load & preprocess PBMC multiome\n",
    "# -----------------------------\n",
    "mdata = mds.load(\"pbmc10k_multiome\", full=True)\n",
    "mdata.var_names_make_unique()\n",
    "print(\"Available modalities:\", list(mdata.mod.keys()))\n",
    "\n",
    "# -----------------------------\n",
    "# RNA preprocessing\n",
    "# -----------------------------\n",
    "rna = mdata.mod['rna']\n",
    "sc.pp.filter_cells(rna, min_genes=200)\n",
    "sc.pp.filter_genes(rna, min_cells=3)\n",
    "sc.pp.normalize_total(rna, target_sum=1e4)\n",
    "sc.pp.log1p(rna)\n",
    "sc.pp.highly_variable_genes(rna, n_top_genes=20, subset=True)\n",
    "\n",
    "# -----------------------------\n",
    "# ATAC preprocessing\n",
    "# -----------------------------\n",
    "atac = mdata.mod['atac']\n",
    "sc.pp.normalize_total(atac, target_sum=1e4)\n",
    "sc.pp.log1p(atac)\n",
    "sc.pp.highly_variable_genes(atac, n_top_genes=5000, flavor=\"seurat_v3\", subset=True)\n",
    "\n",
    "# -----------------------------\n",
    "# ADT preprocessing (optional)\n",
    "# -----------------------------\n",
    "adt = mdata.mod['adt'] if 'adt' in mdata.mod else None\n",
    "if adt is not None:\n",
    "    adt.X = np.log1p(adt.X)\n",
    "    sc.pp.highly_variable_genes(adt, n_top_genes=50, subset=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Build common cells & modality_data\n",
    "# -----------------------------\n",
    "common_cells = rna.obs_names.intersection(atac.obs_names)\n",
    "if adt is not None:\n",
    "    common_cells = common_cells.intersection(adt.obs_names)\n",
    "common_cells = np.array(common_cells)\n",
    "print(\"Number of common cells:\", len(common_cells))\n",
    "\n",
    "rna = rna[common_cells]\n",
    "atac = atac[common_cells]\n",
    "if adt is not None:\n",
    "    adt = adt[common_cells]\n",
    "\n",
    "# -----------------------------\n",
    "# Graph Attention Embedding\n",
    "# -----------------------------\n",
    "class GATEmbedder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=64, out_dim=32, heads=2):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_dim, hidden_dim, heads=heads)\n",
    "        self.gat2 = GATConv(hidden_dim*heads, out_dim, heads=1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def compute_gat_embedding(expr_matrix, k=5):\n",
    "    # Convert sparse matrix to dense if needed\n",
    "    if hasattr(expr_matrix, \"toarray\"):\n",
    "        expr_matrix = expr_matrix.toarray()\n",
    "    elif hasattr(expr_matrix, \"todense\"):\n",
    "        expr_matrix = np.array(expr_matrix.todense())\n",
    "    \n",
    "    # Build kNN edges for GAT graph (simple nearest neighbors)\n",
    "    n_cells = expr_matrix.shape[0]\n",
    "    edge_index = []\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(expr_matrix)\n",
    "    distances, indices = nbrs.kneighbors(expr_matrix)\n",
    "    for i in range(n_cells):\n",
    "        for j in indices[i]:\n",
    "            if i != j:\n",
    "                edge_index.append([i, j])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    x = torch.tensor(expr_matrix, dtype=torch.float).to(DEVICE)\n",
    "    \n",
    "    model = GATEmbedder(in_dim=expr_matrix.shape[1]).to(DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_embed = model(x, edge_index)\n",
    "    return x_embed.cpu().numpy()\n",
    "\n",
    "\n",
    "# Compute GAT embeddings per modality\n",
    "z_rna = compute_gat_embedding(rna.X)\n",
    "z_atac = compute_gat_embedding(atac.X)\n",
    "if adt is not None:\n",
    "    z_adt = compute_gat_embedding(adt.X)\n",
    "\n",
    "modality_data = {'rna': z_rna, 'atac': z_atac}\n",
    "if adt is not None:\n",
    "    modality_data['adt'] = z_adt\n",
    "\n",
    "# -----------------------------\n",
    "# Scaling & train/test split\n",
    "# -----------------------------\n",
    "expression_train, expression_test = {}, {}\n",
    "pseudotime_train, pseudotime_test = {}, {}\n",
    "scalers = {}\n",
    "\n",
    "for mod, data in modality_data.items():\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    scalers[mod] = scaler\n",
    "    train_idx, test_idx = train_test_split(np.arange(data_scaled.shape[0]), test_size=0.2, random_state=SEED)\n",
    "    expression_train[mod] = data_scaled[train_idx]\n",
    "    expression_test[mod] = data_scaled[test_idx]\n",
    "    pseudotime = np.arange(data_scaled.shape[0], dtype=np.float32)\n",
    "    pseudotime_train[mod] = pseudotime[train_idx]\n",
    "    pseudotime_test[mod] = pseudotime[test_idx]\n",
    "\n",
    "fused_train = np.concatenate([expression_train[m] for m in expression_train.keys()], axis=1)\n",
    "fused_test = np.concatenate([expression_test[m] for m in expression_test.keys()], axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Modality splits\n",
    "# -----------------------------\n",
    "modality_dims = {mod: expression_train[mod].shape[1] for mod in expression_train.keys()}\n",
    "starts = np.cumsum([0] + list(modality_dims.values()))[:-1]\n",
    "modality_splits = {}\n",
    "idx = 0\n",
    "for mod, dim in modality_dims.items():\n",
    "    start = idx\n",
    "    end = idx + dim\n",
    "    modality_splits[mod] = (start, end)\n",
    "    idx = end\n",
    "total_features = fused_train.shape[1]\n",
    "selected_gene_names = [f\"feat_{i}\" for i in range(total_features)]\n",
    "print(\"Modality splits:\", modality_splits)\n",
    "\n",
    "# -----------------------------\n",
    "# Adaptive thresholds\n",
    "# -----------------------------\n",
    "class PerGeneAdaptiveThreshold:\n",
    "    def __init__(self, modality_dims, alpha=0.1):\n",
    "        self.thresholds = {mod: {i: 0.0 for i in range(dim)} for mod, dim in modality_dims.items()}\n",
    "        self.alpha = alpha\n",
    "    def update(self, gene_rewards):\n",
    "        for mod, rewards in gene_rewards.items():\n",
    "            for gene_id, reward in rewards.items():\n",
    "                if reward is None or (isinstance(reward, float) and np.isnan(reward)):\n",
    "                    continue\n",
    "                self.thresholds[mod][gene_id] = self.alpha*float(reward) + (1-self.alpha)*self.thresholds[mod].get(gene_id,0.0)\n",
    "    def get(self, mod, gene_id):\n",
    "        return float(self.thresholds.get(mod, {}).get(gene_id,0.0))\n",
    "\n",
    "adaptive_thresholds = PerGeneAdaptiveThreshold(modality_dims)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 8: Adaptive Threshold per modality\n",
    "# -----------------------------\n",
    "class PerGeneAdaptiveThreshold:\n",
    "    def __init__(self, modality_dims, alpha=0.1):\n",
    "        self.thresholds = {mod: {i: 0.0 for i in range(dim)} for mod, dim in modality_dims.items()}\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, gene_rewards):\n",
    "        for mod, rewards in gene_rewards.items():\n",
    "            for gene_id, reward in rewards.items():\n",
    "                if reward is None or (isinstance(reward, float) and np.isnan(reward)):\n",
    "                    continue\n",
    "                self.thresholds[mod][gene_id] = self.alpha * float(reward) + (1 - self.alpha) * self.thresholds[mod].get(gene_id, 0.0)\n",
    "\n",
    "    def get(self, mod, gene_id):\n",
    "        return float(self.thresholds.get(mod, {}).get(gene_id, 0.0))\n",
    "\n",
    "adaptive_thresholds = PerGeneAdaptiveThreshold(modality_dims)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 9: Multi-modal PBMC CRISPR environment\n",
    "# -----------------------------\n",
    "class PBMC_CRISPR_MultiModalEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, expression_dict_or_matrix, pseudotime_dict_or_array, modality_splits,\n",
    "                 max_steps=MAX_STEPS, adaptive_thresholds=None, device='cpu',\n",
    "                 action_magnitude=0.25, perturb_prob=0.1, max_perturb=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Accept either dicts (per-modality) or already-fused matrices\n",
    "        if isinstance(expression_dict_or_matrix, dict):\n",
    "            # build fused matrix in modality_splits order\n",
    "            self.expression_dict = {mod: np.asarray(expression_dict_or_matrix[mod], dtype=np.float32) for mod in modality_splits.keys()}\n",
    "            self.expression = np.concatenate([self.expression_dict[mod] for mod in modality_splits.keys()], axis=1)\n",
    "            # pseudotime: use first modality's pseudotime (cell-level)\n",
    "            self.pseudotime = np.asarray(next(iter(pseudotime_dict_or_array.values())), dtype=np.float32)\n",
    "        else:\n",
    "            self.expression = np.asarray(expression_dict_or_matrix, dtype=np.float32)\n",
    "            self.expression_dict = {}\n",
    "            start = 0\n",
    "            for mod, (s, e) in modality_splits.items():\n",
    "                self.expression_dict[mod] = self.expression[:, s:e]\n",
    "            self.pseudotime = np.asarray(pseudotime_dict_or_array, dtype=np.float32)\n",
    "\n",
    "        self.modality_splits = modality_splits\n",
    "        self.modality_dims = {m: (e - s) for m, (s, e) in modality_splits.items()}\n",
    "        self.n_cells, self.n_genes = self.expression.shape\n",
    "        self.max_steps = max_steps\n",
    "        self.adaptive_thresholds = adaptive_thresholds\n",
    "        self.device = device\n",
    "        self.action_magnitude = action_magnitude\n",
    "        self.perturb_prob = perturb_prob\n",
    "        self.max_perturb = max_perturb\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(self.n_genes,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_genes,), dtype=np.float32)\n",
    "\n",
    "        # bookkeeping\n",
    "        self.current_cell = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.idx = np.random.randint(self.n_cells)\n",
    "        self.state = self.expression[self.idx].copy()\n",
    "        self.original_state = self.state.copy()\n",
    "\n",
    "        eligible_idxs = np.where(np.arange(self.n_cells) > self.idx)[0]\n",
    "        if len(eligible_idxs) == 0:\n",
    "            eligible_idxs = np.array([self.idx])\n",
    "        target_idx = np.random.choice(eligible_idxs)\n",
    "        self.target = self.expression[target_idx].copy()\n",
    "\n",
    "        self.steps = 0\n",
    "        self.history = [self.state.copy()]\n",
    "        self.knockout_genes = set()\n",
    "        self.overexpressed_genes = set()\n",
    "        self._apply_crispr_perturbation()\n",
    "        self.current_cell = 0\n",
    "        return self.state.copy()\n",
    "\n",
    "    def _apply_crispr_perturbation(self):\n",
    "        n_perturb = np.random.randint(1, self.max_perturb + 1)\n",
    "        for _ in range(n_perturb):\n",
    "            gene = np.random.randint(0, self.n_genes)\n",
    "            if np.random.rand() < 0.5:\n",
    "                self.state[gene] = 0.0\n",
    "                self.knockout_genes.add(int(gene))\n",
    "            else:\n",
    "                self.state[gene] = self.state[gene] * 2.0\n",
    "                self.overexpressed_genes.add(int(gene))\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.asarray(action, dtype=np.float32).ravel()\n",
    "        if action.shape[0] != self.n_genes:\n",
    "            raise ValueError(\"Action length mismatch.\")\n",
    "        for i, delta in enumerate(action):\n",
    "            self.state[i] = np.clip(self.state[i] + delta * self.action_magnitude, -5.0, 5.0)\n",
    "\n",
    "        if np.random.rand() < self.perturb_prob:\n",
    "            self._apply_crispr_perturbation()\n",
    "\n",
    "        old_mse = float(np.mean((self.history[-1] - self.target) ** 2))\n",
    "        new_mse = float(np.mean((self.state - self.target) ** 2))\n",
    "        reward = old_mse - new_mse\n",
    "\n",
    "        # subtract adaptive thresholds per modality (if provided)\n",
    "        if self.adaptive_thresholds is not None:\n",
    "            for mod, (start, end) in self.modality_splits.items():\n",
    "                for local_idx, g in enumerate(range(start, end)):\n",
    "                    reward -= self.adaptive_thresholds.get(mod, local_idx)\n",
    "\n",
    "        self.steps += 1\n",
    "        self.history.append(self.state.copy())\n",
    "        terminated = self.steps >= self.max_steps\n",
    "        done = terminated\n",
    "        info = {}\n",
    "        self.current_cell += 1\n",
    "        return self.state.copy(), float(reward), done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Step {self.steps} - state (first 10): {self.state[:10]}\")\n",
    "        print(f\"Knockouts: {sorted(list(self.knockout_genes))[:10]}, Overexpr: {sorted(list(self.overexpressed_genes))[:10]}\")\n",
    "\n",
    "# -----------------------------\n",
    "# SB3 Env wrapper\n",
    "# -----------------------------\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class GRNEnvWrapper(gym.Env):\n",
    "    def __init__(self, base_env):\n",
    "        super().__init__()\n",
    "        self.env = base_env\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.env.n_genes,), dtype=np.float32\n",
    "        )\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        result = self.env.reset(**kwargs)\n",
    "        # Handle Gym >=0.26 returning (obs, info)\n",
    "        if isinstance(result, tuple) and len(result) == 2:\n",
    "            obs, info = result\n",
    "            return np.asarray(obs, dtype=np.float32), info\n",
    "        else:\n",
    "            return np.asarray(result, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        if len(result) == 5:  # Gym >=0.26\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "        return np.asarray(obs, dtype=np.float32), reward, done, info\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        # Optional: delegate seeding to the base environment\n",
    "        if hasattr(self.env, 'seed'):\n",
    "            return self.env.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# make_env_factory (multi-modality aware)\n",
    "# -----------------------------\n",
    "def make_env_factory(expression, pseudotime, modality_splits, adaptive_thresholds,\n",
    "                     perturb_prob=PERTURB_PROB, max_perturb=MAX_PERTURB):\n",
    "    def _init():\n",
    "        base_env = PBMC_CRISPR_MultiModalEnv(\n",
    "            expression_dict_or_matrix=expression,\n",
    "            pseudotime_dict_or_array=pseudotime,\n",
    "            modality_splits=modality_splits,\n",
    "            max_steps=MAX_STEPS,\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            device=DEVICE,\n",
    "            action_magnitude=0.25,\n",
    "            perturb_prob=perturb_prob,\n",
    "            max_perturb=max_perturb\n",
    "        )\n",
    "        return GRNEnvWrapper(base_env)\n",
    "    return _init\n",
    "\n",
    "# -----------------------------\n",
    "# evaluate_and_plot_multi_modality\n",
    "# -----------------------------\n",
    "def evaluate_and_plot_multi_modality(model, algo_name, expression_test, pseudotime_test,\n",
    "                                     gene_names, modality_splits, adaptive_thresholds,\n",
    "                                     n_episodes=50, save_dir=PLOTS_DIR):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    results = []\n",
    "    eval_env_factory = make_env_factory(expression_test, pseudotime_test, modality_splits, adaptive_thresholds)\n",
    "\n",
    "    for mod_name, (start_idx, end_idx) in modality_splits.items():\n",
    "        print(f\"Evaluating modality: {mod_name}\")\n",
    "        for gene_idx in range(start_idx, end_idx):\n",
    "            gene_name = gene_names[gene_idx] if gene_idx < len(gene_names) else f\"g{gene_idx}\"\n",
    "            y_true, y_pred = [], []\n",
    "            perturbed_vals, original_vals, pseudotimes = [], [], []\n",
    "\n",
    "            for ep in range(n_episodes):\n",
    "                env = eval_env_factory()\n",
    "                try:\n",
    "                    obs = env.reset()\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "                original = env.env.original_state.copy()\n",
    "                target = env.env.target.copy()\n",
    "                pt_idx = getattr(env.env, \"current_cell\", 0)\n",
    "                pt_value = float(env.env.pseudotime[pt_idx]) if len(env.env.pseudotime) > 0 else 0.0\n",
    "\n",
    "                done = False\n",
    "                traj_pred = []\n",
    "\n",
    "                while not done:\n",
    "                    try:\n",
    "                        action, _ = model.predict(obs, deterministic=True)\n",
    "                        step_result = env.step(action)\n",
    "                        if len(step_result) == 5:\n",
    "                            obs, reward, terminated, truncated, info = step_result\n",
    "                            done = terminated or truncated\n",
    "                        else:\n",
    "                            obs, reward, done, info = step_result\n",
    "                    except Exception:\n",
    "                        break\n",
    "                    traj_pred.append(env.env.state[gene_idx])\n",
    "\n",
    "                if len(traj_pred) == 0:\n",
    "                    continue\n",
    "\n",
    "                final_state = env.env.history[-1]\n",
    "                delta = float(final_state[gene_idx] - original[gene_idx])\n",
    "                label = 1 if target[gene_idx] > original[gene_idx] else 0\n",
    "                prediction = 1 if delta > 0 else 0\n",
    "\n",
    "                y_true.append(label)\n",
    "                y_pred.append(prediction)\n",
    "                perturbed_vals.append(float(final_state[gene_idx]))\n",
    "                original_vals.append(float(original[gene_idx]))\n",
    "                pseudotimes.append(pt_value)\n",
    "\n",
    "            if len(y_true) == 0:\n",
    "                continue\n",
    "\n",
    "            # metrics\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            try:\n",
    "                auprc = average_precision_score(y_true, y_pred)\n",
    "            except Exception:\n",
    "                auprc = np.nan\n",
    "\n",
    "            mse = mean_squared_error(original_vals, perturbed_vals)\n",
    "            rmse = math.sqrt(mse)\n",
    "            mae = mean_absolute_error(original_vals, perturbed_vals)\n",
    "            r2 = r2_score(original_vals, perturbed_vals)\n",
    "            pc = np.corrcoef(original_vals, perturbed_vals)[0, 1] if np.std(original_vals) != 0 else 0.0\n",
    "\n",
    "            results.append({\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Modality\": mod_name,\n",
    "                \"Gene\": gene_name,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1\": f1,\n",
    "                \"AUPRC\": auprc,\n",
    "                \"Final Expression MSE\": mse,\n",
    "                \"Final Expression RMSE\": rmse,\n",
    "                \"Final Expression MAE\": mae,\n",
    "                \"Final Expression R²\": r2,\n",
    "                \"Final Expression PearsonCorr\": pc\n",
    "            })\n",
    "\n",
    "            # plot pseudotime\n",
    "            try:\n",
    "                df = pd.DataFrame({\n",
    "                    \"pseudotime\": pseudotimes,\n",
    "                    \"original_expression\": original_vals,\n",
    "                    \"perturbed_expression\": perturbed_vals\n",
    "                })\n",
    "                df['delta'] = df['perturbed_expression'] - df['original_expression']\n",
    "                df['label'] = df['delta'].apply(lambda x: \"Up\" if x > 0 else \"Down\")\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                sns.scatterplot(data=df, x=\"pseudotime\", y=\"perturbed_expression\", hue=\"label\", style=\"label\")\n",
    "                sns.lineplot(data=df.sort_values('pseudotime'), x=\"pseudotime\", y=\"perturbed_expression\", lw=1, alpha=0.5)\n",
    "                plt.title(f\"{algo_name} — {mod_name} — {gene_name} Perturbation\")\n",
    "                plt.xlabel(\"Pseudotime\")\n",
    "                plt.ylabel(\"Expression (z-score)\")\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_dir, f\"{algo_name}_{mod_name}_{gene_name}.png\"), dpi=300)\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(\"Plot error:\", e)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# -----------------------------\n",
    "# Custom optimizers (Padam, ASGDAdam, ASGDAmsgrad)\n",
    "# -----------------------------\n",
    "# Implementations included so we can use them as optimizer_class via policy_kwargs in PPO wrappers.\n",
    "# (Identical implementations as earlier; kept minimal here to register classes.)\n",
    "\n",
    "def count_nonzero(tensor):\n",
    "    return int((tensor != 0).sum().item())\n",
    "\n",
    "class ASGDAdam(Optimizer):\n",
    "    \"\"\"ASGD-style optimizer using separate lr_min/lr_max per step.\"\"\"\n",
    "    def __init__(self, params, lr=None, beta1=0.9, beta2=0.999, eps=1e-8,\n",
    "                 lr_min=1e-4, lr_max=3e-4):\n",
    "        defaults = dict(beta1=beta1, beta2=beta2, eps=eps, lr_min=lr_min, lr_max=lr_max)\n",
    "        super().__init__(params, defaults)\n",
    "        self.last_total_nonzero_fmin = 0\n",
    "        self.last_total_nonzero_fmax = 0\n",
    "        self.last_lr = lr_max\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        total_nonzero_fmin, total_nonzero_fmax = 0, 0\n",
    "        for group in self.param_groups:\n",
    "            beta1, beta2, eps = group['beta1'], group['beta2'], group['eps']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                g = p.grad\n",
    "                state = self.state[p]\n",
    "                if not state:\n",
    "                    state['t'] = 0\n",
    "                    state['m'] = torch.zeros_like(p)\n",
    "                    state['v'] = torch.zeros_like(p)\n",
    "                    state['v_prev'] = torch.zeros_like(p)\n",
    "                m, v = state['m'], state['v']\n",
    "                state['t'] += 1\n",
    "                t = state['t']\n",
    "                m.mul_(beta1).add_(g, alpha=1-beta1)\n",
    "                v.mul_(beta2).addcmul_(g, g, value=1-beta2)\n",
    "                dv = v - state['v_prev']\n",
    "                state['v_prev'].copy_(v)\n",
    "                f_min = (dv > 0).to(dtype=torch.int32)\n",
    "                f_max = (dv <= 0).to(dtype=torch.int32)\n",
    "                total_nonzero_fmin += count_nonzero(f_min)\n",
    "                total_nonzero_fmax += count_nonzero(f_max)\n",
    "                mhat = m / (1 - beta1 ** t)\n",
    "                state['step_dir'] = mhat / (v.sqrt().add(eps))\n",
    "        use_lr_min = (total_nonzero_fmax < total_nonzero_fmin) #\n",
    "        self.last_total_nonzero_fmin = total_nonzero_fmin\n",
    "        self.last_total_nonzero_fmax = total_nonzero_fmax\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr_min'] if use_lr_min else group['lr_max']\n",
    "            self.last_lr = lr\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None and 'step_dir' in self.state[p]:\n",
    "                    p.add_(self.state[p]['step_dir'], alpha=-lr)\n",
    "        return loss\n",
    "\n",
    "class ASGDAmsgrad(Optimizer):\n",
    "    \"\"\"ASGD-style optimizer mimicking AMSGrad\"\"\"\n",
    "    def __init__(self, params, lr=None, beta1=0.9, beta2=0.999, eps=1e-8,\n",
    "                 lr_min=1e-5, lr_max=3e-4):\n",
    "        defaults = dict(beta1=beta1, beta2=beta2, eps=eps, lr_min=lr_min, lr_max=lr_max)\n",
    "        super().__init__(params, defaults)\n",
    "        self.last_total_nonzero_fmin = 0\n",
    "        self.last_total_nonzero_fmax = 0\n",
    "        self.last_lr = lr_max\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        total_nonzero_fmin, total_nonzero_fmax = 0, 0\n",
    "        for group in self.param_groups:\n",
    "            beta1, beta2, eps = group['beta1'], group['beta2'], group['eps']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                g = p.grad\n",
    "                state = self.state[p]\n",
    "                if not state:\n",
    "                    state['t'] = 0\n",
    "                    state['m'] = torch.zeros_like(p)\n",
    "                    state['v'] = torch.zeros_like(p)\n",
    "                    state['v_hat'] = torch.zeros_like(p)\n",
    "                    state['v_prev'] = torch.zeros_like(p)\n",
    "                m, v, v_hat = state['m'], state['v'], state['v_hat']\n",
    "                state['t'] += 1\n",
    "                t = state['t']\n",
    "                m.mul_(beta1).add_(g, alpha=1-beta1)\n",
    "                v.mul_(beta2).addcmul_(g, g, value=1-beta2)\n",
    "                torch.maximum(v_hat, v, out=v_hat)\n",
    "                denom = v_hat.sqrt().add(eps)\n",
    "                dv = v - state['v_prev']\n",
    "                state['v_prev'].copy_(v)\n",
    "                f_min = (dv > 0).to(dtype=torch.int32)\n",
    "                f_max = (dv <= 0).to(dtype=torch.int32)\n",
    "                total_nonzero_fmin += count_nonzero(f_min)\n",
    "                total_nonzero_fmax += count_nonzero(f_max)\n",
    "                mhat = m / (1 - beta1 ** t)\n",
    "                state['step_dir'] = mhat / denom\n",
    "        use_lr_min = (total_nonzero_fmax <  total_nonzero_fmin) # \n",
    "        self.last_total_nonzero_fmin = total_nonzero_fmin\n",
    "        self.last_total_nonzero_fmax = total_nonzero_fmax\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr_min'] if use_lr_min else group['lr_max']\n",
    "            self.last_lr = lr\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None and 'step_dir' in self.state[p]:\n",
    "                    p.add_(self.state[p]['step_dir'], alpha=-lr)\n",
    "        return loss\n",
    "\n",
    "class Padam(Optimizer):\n",
    "    \"\"\"Padam optimizer\"\"\"\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9,0.999), eps=1e-8, weight_decay=0, amsgrad=False, p=0.125):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad, p=p)\n",
    "        super().__init__(params, defaults)\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None: continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Padam does not support sparse gradients')\n",
    "                state = self.state[p]\n",
    "                amsgrad = group['amsgrad']\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                    if amsgrad:\n",
    "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                if amsgrad:\n",
    "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1-beta1)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1-beta2)\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                if amsgrad:\n",
    "                    torch.maximum(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
    "                    denom = (max_exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
    "                else:\n",
    "                    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
    "                step_size = group['lr'] / bias_correction1\n",
    "                denom = denom.pow(group['p'])\n",
    "                if group['weight_decay'] != 0:\n",
    "                    grad = grad.add(p.data, alpha=group['weight_decay'])\n",
    "                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "# --------------------------\n",
    "# PPO Wrappers\n",
    "# --------------------------\n",
    "class PPOAdamAMSGrad(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": optim.Adam, \"optimizer_kwargs\": {\"amsgrad\": True}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOAdam(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": optim.Adam})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOSGD(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": optim.SGD})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOPadam(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": Padam, \"optimizer_kwargs\": {\"amsgrad\": True}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOASGDAdam(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": ASGDAdam, \"optimizer_kwargs\": {\"lr_min\":1e-7, \"lr_max\":1e-3}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOASGDAmsgrad(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": ASGDAmsgrad, \"optimizer_kwargs\": {\"lr_min\":1e-7, \"lr_max\":1e-3}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# -----------------------------\n",
    "# Training orchestration: train_compare_optimizers\n",
    "# -----------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "def train_and_evaluate_optimizers(modality_choice=\"all\",\n",
    "                                  expression_train=None, pseudotime_train=None,\n",
    "                                  expression_test=None, pseudotime_test=None,\n",
    "                                  modality_splits=None, gene_names=None,\n",
    "                                  adaptive_thresholds=None,\n",
    "                                  optimizers_to_run=None,\n",
    "                                  train_steps=10000,\n",
    "                                  save_dir=\"outputs\"):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    if optimizers_to_run is None:\n",
    "        optimizers_to_run = [\"adam\", \"amsgrad\"]\n",
    "\n",
    "    algo_map = {\n",
    "        \"sgd\": PPOSGD,\n",
    "        \"amsgrad\": PPOAdamAMSGrad,\n",
    "        \"adam\": PPOAdam,\n",
    "        \"padam\": PPOPadam,\n",
    "        \"asgdadam\": PPOASGDAdam,\n",
    "        \"asgdaamsgrad\": PPOASGDAmsgrad,\n",
    "    }\n",
    "\n",
    "    base_kwargs = {\n",
    "        \"gamma\": 0.99,\n",
    "        \"gae_lambda\": 0.95,\n",
    "        \"clip_range\": 0.2,\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"vf_coef\": 0.5,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"policy_kwargs\": dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])], activation_fn=nn.Tanh)\n",
    "    }\n",
    "\n",
    "    # -----------------------------\n",
    "    # Modality-specific data\n",
    "    # -----------------------------\n",
    "    if modality_choice == \"all\":\n",
    "        expr_train_mod = expression_train\n",
    "        expr_test_mod = expression_test\n",
    "        pseudo_train_mod = pseudotime_train[next(iter(pseudotime_train.keys()))]  # pick any modality's pseudotime\n",
    "        pseudo_test_mod = pseudotime_test[next(iter(pseudotime_test.keys()))]\n",
    "        gene_names_mod = gene_names\n",
    "        splits_for_env_mod = modality_splits\n",
    "    else:\n",
    "        start, end = modality_splits[modality_choice]\n",
    "        expr_train_mod = expression_train[:, start:end]\n",
    "        expr_test_mod = expression_test[:, start:end]\n",
    "        pseudo_train_mod = pseudotime_train[modality_choice]\n",
    "        pseudo_test_mod = pseudotime_test[modality_choice]\n",
    "        splits_for_env_mod = {modality_choice: (0, end - start)}\n",
    "        gene_names_mod = [f\"{modality_choice}_{i}\" for i in range(end - start)]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Environments\n",
    "    # -----------------------------\n",
    "    train_env = DummyVecEnv([make_env_factory(expr_train_mod, pseudo_train_mod, splits_for_env_mod, adaptive_thresholds)])\n",
    "    eval_env = DummyVecEnv([make_env_factory(expr_test_mod, pseudo_test_mod, splits_for_env_mod, adaptive_thresholds)])\n",
    "    eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
    "\n",
    "    trained_models = {}\n",
    "    results_reward = {}\n",
    "    train_metrics_df = []\n",
    "    test_metrics_df = []\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training loop\n",
    "    # -----------------------------\n",
    "    for opt_name in optimizers_to_run:\n",
    "        PPOClass = algo_map[opt_name]\n",
    "        print(f\"\\n--- Training {opt_name} on modality={modality_choice} ---\")\n",
    "\n",
    "        model = PPOClass(\"MlpPolicy\", train_env, verbose=1, seed=SEED, **base_kwargs)\n",
    "        model.learn(total_timesteps=train_steps)\n",
    "        trained_models[opt_name] = model\n",
    "\n",
    "        # Evaluate mean reward on test environment\n",
    "        mean_r, std_r = evaluate_model_sb3(model, eval_env, n_eval_episodes=N_EVAL_EPISODES)\n",
    "        results_reward[opt_name] = (mean_r, std_r)\n",
    "        print(f\"Eval mean reward ({opt_name}): {mean_r:.4f} ± {std_r:.4f}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Per-gene evaluation on training data\n",
    "        # -----------------------------\n",
    "# -----------------------------\n",
    "# Per-gene evaluation on training data\n",
    "# -----------------------------\n",
    "# -----------------------------\n",
    "# Per-gene evaluation on training data\n",
    "# -----------------------------\n",
    "        df_train = evaluate_and_plot_multi_modality(\n",
    "            model=model,\n",
    "            algo_name=f\"{opt_name}_train\",\n",
    "            expression_test=expr_train_mod,\n",
    "            pseudotime_test=pseudo_train_mod,\n",
    "            modality_splits=splits_for_env_mod,  # pass the modality splits\n",
    "            gene_names=gene_names_mod,\n",
    "            encoder_path=\"gcn_encoder.pth\",\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            n_episodes=30,\n",
    "            save_dir=PLOTS_DIR\n",
    "        )\n",
    "        train_metrics_df.append(df_train)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Per-gene evaluation on test data\n",
    "        # -----------------------------\n",
    "        df_test = evaluate_and_plot_multi_modality(\n",
    "            model=model,\n",
    "            algo_name=f\"{opt_name}_test\",\n",
    "            expression_test=expr_test_mod,\n",
    "            pseudotime_test=pseudo_test_mod,\n",
    "            modality_splits=splits_for_env_mod,\n",
    "            gene_names=gene_names_mod,\n",
    "            encoder_path=\"gcn_encoder.pth\",\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            n_episodes=30,\n",
    "            save_dir=PLOTS_DIR\n",
    "        )\n",
    "        test_metrics_df.append(df_test)\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save training metrics\n",
    "    # -----------------------------\n",
    "    final_train_df = pd.concat(train_metrics_df, ignore_index=True)\n",
    "    final_train_df.to_csv(os.path.join(save_dir, f\"training_per_gene_metrics_{modality_choice}.csv\"), index=False)\n",
    "    train_summary_df = final_train_df.groupby(\"Algorithm\").mean(numeric_only=True)\n",
    "    train_summary_df.to_csv(os.path.join(save_dir, f\"training_overall_metrics_{modality_choice}.csv\"))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save testing metrics\n",
    "    # -----------------------------\n",
    "    final_test_df = pd.concat(test_metrics_df, ignore_index=True)\n",
    "    final_test_df.to_csv(os.path.join(save_dir, f\"testing_per_gene_metrics_{modality_choice}.csv\"), index=False)\n",
    "    test_summary_df = final_test_df.groupby(\"Algorithm\").mean(numeric_only=True)\n",
    "    test_summary_df.to_csv(os.path.join(save_dir, f\"testing_overall_metrics_{modality_choice}.csv\"))\n",
    "\n",
    "    print(f\"\\n✅ Training & evaluation complete for all optimizers on modality={modality_choice}.\")\n",
    "\n",
    "    return trained_models, results_reward\n",
    "\n",
    "adaptive_thresholds = PerGeneAdaptiveThreshold(modality_dims)\n",
    "trained_models, rewards = train_and_evaluate_optimizers(\n",
    "    modality_choice=\"rna\",  # or \"all\", \"atac\", \"adt\"\n",
    "    expression_train=fused_train,\n",
    "    pseudotime_train=pseudotime_train,\n",
    "    expression_test=fused_test,\n",
    "    pseudotime_test=pseudotime_test,\n",
    "    modality_splits=modality_splits,\n",
    "    gene_names=selected_gene_names,\n",
    "    adaptive_thresholds=adaptive_thresholds,\n",
    "    optimizers_to_run=[\"adam\",\"amsgrad\"],\n",
    "    train_steps=20000,\n",
    "    save_dir=\"outputs\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc0c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0bb4436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336af73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c2472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
