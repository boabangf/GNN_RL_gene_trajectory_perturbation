{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6426e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muon as mu\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a422ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–  File filtered_feature_bc_matrix.h5 from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/filtered_feature_bc_matrix.h5\n",
      "â–  Checksum is validated (md5) for filtered_feature_bc_matrix.h5\n",
      "â–  File atac_fragments.tsv.gz from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_fragments.tsv.gz\n",
      "â–  Checksum is validated (md5) for atac_fragments.tsv.gz\n",
      "â–  File atac_fragments.tsv.gz.tbi from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_fragments.tsv.gz.tbi\n",
      "â–  Checksum is validated (md5) for atac_fragments.tsv.gz.tbi\n",
      "â–  File atac_peaks.bed from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_peaks.bed\n",
      "â–  Checksum is validated (md5) for atac_peaks.bed\n",
      "â–  File atac_peak_annotation.tsv from pbmc10k_multiome has been found at /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_peak_annotation.tsv\n",
      "â–  Checksum is validated (md5) for atac_peak_annotation.tsv\n",
      "â–  Loading filtered_feature_bc_matrix.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudatasets/core.py:203: UserWarning: Dataset is in the 10X .h5 format and can't be loaded as backed.\n",
      "  warn(\"Dataset is in the 10X .h5 format and can't be loaded as backed.\")\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/anndata/_core/anndata.py:1776: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added `interval` annotation for features from /Users/boabangfrancis/mudatasets/pbmc10k_multiome/filtered_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/anndata/_core/anndata.py:1776: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudata/_core/mudata.py:1598: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"var\", axis=0, join_common=join_common)\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudata/_core/mudata.py:947: UserWarning: var_names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  warnings.warn(\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/mudata/_core/mudata.py:1461: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"obs\", axis=1, join_common=join_common)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added peak annotation from /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_peak_annotation.tsv to .uns['atac']['peak_annotation']\n",
      "Added gene names to peak annotation in .uns['atac']['peak_annotation']\n",
      "Located fragments file: /Users/boabangfrancis/mudatasets/pbmc10k_multiome/atac_fragments.tsv.gz\n",
      "pysam is not available. It is required to work with the fragments file.                 Install pysam from PyPI (`pip install pysam`)                 or from GitHub (`pip install git+https://github.com/pysam-developers/pysam`)\n",
      "Available modalities: ['rna', 'atac']\n",
      "Number of common cells: 1000\n",
      "{'rna': (1000, 4), 'atac': (1000, 4)}\n",
      "Modality splits: {'rna': (0, 4), 'atac': (4, 8)}\n",
      "Fused train shape: (800, 8)\n",
      "Modality splits: {'rna': (0, 4), 'atac': (4, 8)}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Full updated notebook cell: PBMC Multi-modal PPO with GAT embeddings\n",
    "# -----------------------------\n",
    "# Imports & settings\n",
    "# -----------------------------\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import muon as mu\n",
    "import mudatasets as mds\n",
    "import scanpy as sc\n",
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "from torch import optim\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "# ðŸ“¦ Imports\n",
    "import cptac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# PyTorch Geometric for GAT embeddings\n",
    "# -----------------------------\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility & device\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "MAX_STEPS = 100\n",
    "PERTURB_PROB = 0.5\n",
    "MAX_PERTURB = 10\n",
    "N_EVAL_EPISODES = 30\n",
    "OUT_DIR = \"pbmc_multi_output\"\n",
    "PLOTS_DIR = os.path.join(OUT_DIR, \"pseudotime_plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Load & preprocess PBMC multiome\n",
    "# -----------------------------\n",
    "mdata = mds.load(\"pbmc10k_multiome\", full=True)\n",
    "mdata.var_names_make_unique()\n",
    "print(\"Available modalities:\", list(mdata.mod.keys()))\n",
    "\n",
    "# Select a small subset of cells (e.g., 1000)\n",
    "np.random.seed(42)\n",
    "subset_cells = np.random.choice(mdata.mod['rna'].obs_names, size=1000, replace=False)\n",
    "\n",
    "# Subset each modality\n",
    "rna = mdata.mod['rna'][subset_cells].copy()\n",
    "atac = mdata.mod['atac'][subset_cells].copy()\n",
    "adt = mdata.mod['adt'][subset_cells].copy() if 'adt' in mdata.mod else None\n",
    "\n",
    "# -----------------------------\n",
    "# Build common cell indices\n",
    "# -----------------------------\n",
    "common_cells = rna.obs_names.intersection(atac.obs_names)\n",
    "if adt is not None:\n",
    "    common_cells = common_cells.intersection(adt.obs_names)\n",
    "common_cells = np.array(common_cells)\n",
    "print(\"Number of common cells:\", len(common_cells))\n",
    "\n",
    "# -----------------------------\n",
    "# Sparse matrix access instead of slicing AnnData\n",
    "# -----------------------------\n",
    "rna_X = csr_matrix(rna.X)\n",
    "atac_X = csr_matrix(atac.X)\n",
    "# ADT (optional)\n",
    "if adt is not None:\n",
    "    adt_X = csr_matrix(adt.X)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# -----------------------------\n",
    "# Simple GAT encoder\n",
    "# -----------------------------\n",
    "import torch\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class SimpleGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=8, out_dim=4, heads=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_dim, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_dim*heads, out_dim, heads=1, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# -----------------------------\n",
    "# kNN graph helper\n",
    "# -----------------------------\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import torch\n",
    "\n",
    "def compute_knn_graph(X, k=5):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, metric='cosine').fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    edge_index = []\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in indices[i]:\n",
    "            if i != j:\n",
    "                edge_index.append([i, j])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "# -----------------------------\n",
    "# Compute embeddings\n",
    "# -----------------------------\n",
    "def gat_embedding(X_np):\n",
    "    X = torch.tensor(X_np, dtype=torch.float32)\n",
    "    edge_index = compute_knn_graph(X_np, k=3)\n",
    "    model = SimpleGAT(in_dim=X.shape[1])\n",
    "    with torch.no_grad():\n",
    "        Z = model(X, edge_index)\n",
    "    return Z.numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# Run embeddings\n",
    "# -----------------------------\n",
    "z_rna = gat_embedding(rna_X.toarray())\n",
    "z_atac = gat_embedding(atac_X.toarray())\n",
    "if adt is not None:\n",
    "    z_adt = gat_embedding(adt_X.toarray())\n",
    "\n",
    "modality_data = {'rna': z_rna, 'atac': z_atac}\n",
    "if adt is not None:\n",
    "    modality_data['adt'] = z_adt\n",
    "\n",
    "print({k:v.shape for k,v in modality_data.items()})\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Scale & train/test split\n",
    "# -----------------------------\n",
    "expression_train, expression_test = {}, {}\n",
    "pseudotime_train, pseudotime_test = {}, {}\n",
    "scalers = {}\n",
    "\n",
    "for mod, data in modality_data.items():\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    scalers[mod] = scaler\n",
    "    train_idx, test_idx = train_test_split(np.arange(data_scaled.shape[0]), test_size=0.2, random_state=SEED)\n",
    "    expression_train[mod] = data_scaled[train_idx]\n",
    "    expression_test[mod] = data_scaled[test_idx]\n",
    "    pseudotime = np.arange(data_scaled.shape[0], dtype=np.float32)\n",
    "    pseudotime_train[mod] = pseudotime[train_idx]\n",
    "    pseudotime_test[mod] = pseudotime[test_idx]\n",
    "\n",
    "# -----------------------------\n",
    "# Fuse modalities\n",
    "# -----------------------------\n",
    "fused_train = np.concatenate([expression_train[m] for m in expression_train.keys()], axis=1)\n",
    "fused_test = np.concatenate([expression_test[m] for m in expression_test.keys()], axis=1)\n",
    "\n",
    "modality_dims = {mod: expression_train[mod].shape[1] for mod in expression_train.keys()}\n",
    "starts = np.cumsum([0] + list(modality_dims.values()))[:-1]\n",
    "modality_splits = {}\n",
    "idx = 0\n",
    "for mod, dim in modality_dims.items():\n",
    "    modality_splits[mod] = (idx, idx+dim)\n",
    "    idx += dim\n",
    "\n",
    "print(\"Modality splits:\", modality_splits)\n",
    "print(\"Fused train shape:\", fused_train.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "# -----------------------------\n",
    "# Scaling & train/test split\n",
    "# -----------------------------\n",
    "expression_train, expression_test = {}, {}\n",
    "pseudotime_train, pseudotime_test = {}, {}\n",
    "scalers = {}\n",
    "\n",
    "for mod, data in modality_data.items():\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    scalers[mod] = scaler\n",
    "    train_idx, test_idx = train_test_split(np.arange(data_scaled.shape[0]), test_size=0.2, random_state=SEED)\n",
    "    expression_train[mod] = data_scaled[train_idx]\n",
    "    expression_test[mod] = data_scaled[test_idx]\n",
    "    pseudotime = np.arange(data_scaled.shape[0], dtype=np.float32)\n",
    "    pseudotime_train[mod] = pseudotime[train_idx]\n",
    "    pseudotime_test[mod] = pseudotime[test_idx]\n",
    "\n",
    "fused_train = np.concatenate([expression_train[m] for m in expression_train.keys()], axis=1)\n",
    "fused_test = np.concatenate([expression_test[m] for m in expression_test.keys()], axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Modality splits\n",
    "# -----------------------------\n",
    "modality_dims = {mod: expression_train[mod].shape[1] for mod in expression_train.keys()}\n",
    "starts = np.cumsum([0] + list(modality_dims.values()))[:-1]\n",
    "modality_splits = {}\n",
    "idx = 0\n",
    "for mod, dim in modality_dims.items():\n",
    "    start = idx\n",
    "    end = idx + dim\n",
    "    modality_splits[mod] = (start, end)\n",
    "    idx = end\n",
    "total_features = fused_train.shape[1]\n",
    "selected_gene_names = [f\"feat_{i}\" for i in range(total_features)]\n",
    "print(\"Modality splits:\", modality_splits)\n",
    "\n",
    "# -----------------------------\n",
    "# Adaptive thresholds\n",
    "# -----------------------------\n",
    "class PerGeneAdaptiveThreshold:\n",
    "    def __init__(self, modality_dims, alpha=0.1):\n",
    "        self.thresholds = {mod: {i: 0.0 for i in range(dim)} for mod, dim in modality_dims.items()}\n",
    "        self.alpha = alpha\n",
    "    def update(self, gene_rewards):\n",
    "        for mod, rewards in gene_rewards.items():\n",
    "            for gene_id, reward in rewards.items():\n",
    "                if reward is None or (isinstance(reward, float) and np.isnan(reward)):\n",
    "                    continue\n",
    "                self.thresholds[mod][gene_id] = self.alpha*float(reward) + (1-self.alpha)*self.thresholds[mod].get(gene_id,0.0)\n",
    "    def get(self, mod, gene_id):\n",
    "        return float(self.thresholds.get(mod, {}).get(gene_id,0.0))\n",
    "\n",
    "adaptive_thresholds = PerGeneAdaptiveThreshold(modality_dims)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Step 9: Multi-modal PBMC CRISPR environment\n",
    "# -----------------------------\n",
    "class PBMC_CRISPR_MultiModalEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, expression_dict_or_matrix, pseudotime_dict_or_array, modality_splits,\n",
    "                 max_steps=MAX_STEPS, adaptive_thresholds=None, device='cpu',\n",
    "                 action_magnitude=0.25, perturb_prob=0.1, max_perturb=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Accept either dicts (per-modality) or already-fused matrices\n",
    "        if isinstance(expression_dict_or_matrix, dict):\n",
    "            # build fused matrix in modality_splits order\n",
    "            self.expression_dict = {mod: np.asarray(expression_dict_or_matrix[mod], dtype=np.float32) for mod in modality_splits.keys()}\n",
    "            self.expression = np.concatenate([self.expression_dict[mod] for mod in modality_splits.keys()], axis=1)\n",
    "            # pseudotime: use first modality's pseudotime (cell-level)\n",
    "            self.pseudotime = np.asarray(next(iter(pseudotime_dict_or_array.values())), dtype=np.float32)\n",
    "        else:\n",
    "            self.expression = np.asarray(expression_dict_or_matrix, dtype=np.float32)\n",
    "            self.expression_dict = {}\n",
    "            start = 0\n",
    "            for mod, (s, e) in modality_splits.items():\n",
    "                self.expression_dict[mod] = self.expression[:, s:e]\n",
    "            self.pseudotime = np.asarray(pseudotime_dict_or_array, dtype=np.float32)\n",
    "\n",
    "        self.modality_splits = modality_splits\n",
    "        self.modality_dims = {m: (e - s) for m, (s, e) in modality_splits.items()}\n",
    "        self.n_cells, self.n_genes = self.expression.shape\n",
    "        self.max_steps = max_steps\n",
    "        self.adaptive_thresholds = adaptive_thresholds\n",
    "        self.device = device\n",
    "        self.action_magnitude = action_magnitude\n",
    "        self.perturb_prob = perturb_prob\n",
    "        self.max_perturb = max_perturb\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(self.n_genes,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_genes,), dtype=np.float32)\n",
    "\n",
    "        # bookkeeping\n",
    "        self.current_cell = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.idx = np.random.randint(self.n_cells)\n",
    "        self.state = self.expression[self.idx].copy()\n",
    "        self.original_state = self.state.copy()\n",
    "\n",
    "        eligible_idxs = np.where(np.arange(self.n_cells) > self.idx)[0]\n",
    "        if len(eligible_idxs) == 0:\n",
    "            eligible_idxs = np.array([self.idx])\n",
    "        target_idx = np.random.choice(eligible_idxs)\n",
    "        self.target = self.expression[target_idx].copy()\n",
    "\n",
    "        self.steps = 0\n",
    "        self.history = [self.state.copy()]\n",
    "        self.knockout_genes = set()\n",
    "        self.overexpressed_genes = set()\n",
    "        self._apply_crispr_perturbation()\n",
    "        self.current_cell = 0\n",
    "        return self.state.copy()\n",
    "\n",
    "    def _apply_crispr_perturbation(self):\n",
    "        n_perturb = np.random.randint(1, self.max_perturb + 1)\n",
    "        for _ in range(n_perturb):\n",
    "            gene = np.random.randint(0, self.n_genes)\n",
    "            if np.random.rand() < 0.5:\n",
    "                self.state[gene] = 0.0\n",
    "                self.knockout_genes.add(int(gene))\n",
    "            else:\n",
    "                self.state[gene] = self.state[gene] * 2.0\n",
    "                self.overexpressed_genes.add(int(gene))\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.asarray(action, dtype=np.float32).ravel()\n",
    "        if action.shape[0] != self.n_genes:\n",
    "            raise ValueError(\"Action length mismatch.\")\n",
    "        for i, delta in enumerate(action):\n",
    "            self.state[i] = np.clip(self.state[i] + delta * self.action_magnitude, -5.0, 5.0)\n",
    "\n",
    "        if np.random.rand() < self.perturb_prob:\n",
    "            self._apply_crispr_perturbation()\n",
    "\n",
    "        old_mse = float(np.mean((self.history[-1] - self.target) ** 2))\n",
    "        new_mse = float(np.mean((self.state - self.target) ** 2))\n",
    "        reward = old_mse - new_mse\n",
    "\n",
    "        # subtract adaptive thresholds per modality (if provided)\n",
    "        if self.adaptive_thresholds is not None:\n",
    "            for mod, (start, end) in self.modality_splits.items():\n",
    "                for local_idx, g in enumerate(range(start, end)):\n",
    "                    reward -= self.adaptive_thresholds.get(mod, local_idx)\n",
    "\n",
    "        self.steps += 1\n",
    "        self.history.append(self.state.copy())\n",
    "        terminated = self.steps >= self.max_steps\n",
    "        done = terminated\n",
    "        info = {}\n",
    "        self.current_cell += 1\n",
    "        return self.state.copy(), float(reward), done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Step {self.steps} - state (first 10): {self.state[:10]}\")\n",
    "        print(f\"Knockouts: {sorted(list(self.knockout_genes))[:10]}, Overexpr: {sorted(list(self.overexpressed_genes))[:10]}\")\n",
    "\n",
    "# -----------------------------\n",
    "# SB3 Env wrapper\n",
    "# -----------------------------\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class GRNEnvWrapper(gym.Env):\n",
    "    def __init__(self, base_env):\n",
    "        super().__init__()\n",
    "        self.env = base_env\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.env.n_genes,), dtype=np.float32\n",
    "        )\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        result = self.env.reset(**kwargs)\n",
    "        # Handle Gym >=0.26 returning (obs, info)\n",
    "        if isinstance(result, tuple) and len(result) == 2:\n",
    "            obs, info = result\n",
    "            return np.asarray(obs, dtype=np.float32), info\n",
    "        else:\n",
    "            return np.asarray(result, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        if len(result) == 5:  # Gym >=0.26\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "        return np.asarray(obs, dtype=np.float32), reward, done, info\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        # Optional: delegate seeding to the base environment\n",
    "        if hasattr(self.env, 'seed'):\n",
    "            return self.env.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# make_env_factory (multi-modality aware)\n",
    "# -----------------------------\n",
    "def make_env_factory(expression, pseudotime, modality_splits, adaptive_thresholds,\n",
    "                     perturb_prob=PERTURB_PROB, max_perturb=MAX_PERTURB):\n",
    "    def _init():\n",
    "        base_env = PBMC_CRISPR_MultiModalEnv(\n",
    "            expression_dict_or_matrix=expression,\n",
    "            pseudotime_dict_or_array=pseudotime,\n",
    "            modality_splits=modality_splits,\n",
    "            max_steps=MAX_STEPS,\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            device=DEVICE,\n",
    "            action_magnitude=0.25,\n",
    "            perturb_prob=perturb_prob,\n",
    "            max_perturb=max_perturb\n",
    "        )\n",
    "        return GRNEnvWrapper(base_env)\n",
    "    return _init\n",
    "\n",
    "# -----------------------------\n",
    "# evaluate_and_plot_multi_modality\n",
    "# -----------------------------\n",
    "def evaluate_and_plot_multi_modality(model, algo_name, expression_test, pseudotime_test,\n",
    "                                     gene_names, modality_splits, adaptive_thresholds,\n",
    "                                     n_episodes=50, save_dir=PLOTS_DIR):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    results = []\n",
    "    eval_env_factory = make_env_factory(expression_test, pseudotime_test, modality_splits, adaptive_thresholds)\n",
    "\n",
    "    for mod_name, (start_idx, end_idx) in modality_splits.items():\n",
    "        print(f\"Evaluating modality: {mod_name}\")\n",
    "        for gene_idx in range(start_idx, end_idx):\n",
    "            gene_name = gene_names[gene_idx] if gene_idx < len(gene_names) else f\"g{gene_idx}\"\n",
    "            y_true, y_pred = [], []\n",
    "            perturbed_vals, original_vals, pseudotimes = [], [], []\n",
    "\n",
    "            for ep in range(n_episodes):\n",
    "                env = eval_env_factory()\n",
    "                try:\n",
    "                    obs = env.reset()\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "                original = env.env.original_state.copy()\n",
    "                target = env.env.target.copy()\n",
    "                pt_idx = getattr(env.env, \"current_cell\", 0)\n",
    "                pt_value = float(env.env.pseudotime[pt_idx]) if len(env.env.pseudotime) > 0 else 0.0\n",
    "\n",
    "                done = False\n",
    "                traj_pred = []\n",
    "\n",
    "                while not done:\n",
    "                    try:\n",
    "                        action, _ = model.predict(obs, deterministic=True)\n",
    "                        step_result = env.step(action)\n",
    "                        if len(step_result) == 5:\n",
    "                            obs, reward, terminated, truncated, info = step_result\n",
    "                            done = terminated or truncated\n",
    "                        else:\n",
    "                            obs, reward, done, info = step_result\n",
    "                    except Exception:\n",
    "                        break\n",
    "                    traj_pred.append(env.env.state[gene_idx])\n",
    "\n",
    "                if len(traj_pred) == 0:\n",
    "                    continue\n",
    "\n",
    "                final_state = env.env.history[-1]\n",
    "                delta = float(final_state[gene_idx] - original[gene_idx])\n",
    "                label = 1 if target[gene_idx] > original[gene_idx] else 0\n",
    "                prediction = 1 if delta > 0 else 0\n",
    "\n",
    "                y_true.append(label)\n",
    "                y_pred.append(prediction)\n",
    "                perturbed_vals.append(float(final_state[gene_idx]))\n",
    "                original_vals.append(float(original[gene_idx]))\n",
    "                pseudotimes.append(pt_value)\n",
    "\n",
    "            if len(y_true) == 0:\n",
    "                continue\n",
    "\n",
    "            # metrics\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "            try:\n",
    "                auprc = average_precision_score(y_true, y_pred)\n",
    "            except Exception:\n",
    "                auprc = np.nan\n",
    "\n",
    "            mse = mean_squared_error(original_vals, perturbed_vals)\n",
    "            rmse = math.sqrt(mse)\n",
    "            mae = mean_absolute_error(original_vals, perturbed_vals)\n",
    "            r2 = r2_score(original_vals, perturbed_vals)\n",
    "            pc = np.corrcoef(original_vals, perturbed_vals)[0, 1] if np.std(original_vals) != 0 else 0.0\n",
    "\n",
    "            results.append({\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Modality\": mod_name,\n",
    "                \"Gene\": gene_name,\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1\": f1,\n",
    "                \"AUPRC\": auprc,\n",
    "                \"Final Expression MSE\": mse,\n",
    "                \"Final Expression RMSE\": rmse,\n",
    "                \"Final Expression MAE\": mae,\n",
    "                \"Final Expression RÂ²\": r2,\n",
    "                \"Final Expression PearsonCorr\": pc\n",
    "            })\n",
    "\n",
    "            # plot pseudotime\n",
    "            try:\n",
    "                df = pd.DataFrame({\n",
    "                    \"pseudotime\": pseudotimes,\n",
    "                    \"original_expression\": original_vals,\n",
    "                    \"perturbed_expression\": perturbed_vals\n",
    "                })\n",
    "                df['delta'] = df['perturbed_expression'] - df['original_expression']\n",
    "                df['label'] = df['delta'].apply(lambda x: \"Up\" if x > 0 else \"Down\")\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                sns.scatterplot(data=df, x=\"pseudotime\", y=\"perturbed_expression\", hue=\"label\", style=\"label\")\n",
    "                sns.lineplot(data=df.sort_values('pseudotime'), x=\"pseudotime\", y=\"perturbed_expression\", lw=1, alpha=0.5)\n",
    "                plt.title(f\"{algo_name} â€” {mod_name} â€” {gene_name} Perturbation\")\n",
    "                plt.xlabel(\"Pseudotime\")\n",
    "                plt.ylabel(\"Expression (z-score)\")\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_dir, f\"{algo_name}_{mod_name}_{gene_name}.png\"), dpi=300)\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(\"Plot error:\", e)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# -----------------------------\n",
    "# Custom optimizers (Padam, ASGDAdam, ASGDAmsgrad)\n",
    "# -----------------------------\n",
    "# Implementations included so we can use them as optimizer_class via policy_kwargs in PPO wrappers.\n",
    "# (Identical implementations as earlier; kept minimal here to register classes.)\n",
    "\n",
    "def count_nonzero(tensor):\n",
    "    return int((tensor != 0).sum().item())\n",
    "\n",
    "class ASGDAdam(Optimizer):\n",
    "    \"\"\"ASGD-style optimizer using separate lr_min/lr_max per step.\"\"\"\n",
    "    def __init__(self, params, lr=None, beta1=0.9, beta2=0.999, eps=1e-8,\n",
    "                 lr_min=1e-4, lr_max=3e-4):\n",
    "        defaults = dict(beta1=beta1, beta2=beta2, eps=eps, lr_min=lr_min, lr_max=lr_max)\n",
    "        super().__init__(params, defaults)\n",
    "        self.last_total_nonzero_fmin = 0\n",
    "        self.last_total_nonzero_fmax = 0\n",
    "        self.last_lr = lr_max\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        total_nonzero_fmin, total_nonzero_fmax = 0, 0\n",
    "        for group in self.param_groups:\n",
    "            beta1, beta2, eps = group['beta1'], group['beta2'], group['eps']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                g = p.grad\n",
    "                state = self.state[p]\n",
    "                if not state:\n",
    "                    state['t'] = 0\n",
    "                    state['m'] = torch.zeros_like(p)\n",
    "                    state['v'] = torch.zeros_like(p)\n",
    "                    state['v_prev'] = torch.zeros_like(p)\n",
    "                m, v = state['m'], state['v']\n",
    "                state['t'] += 1\n",
    "                t = state['t']\n",
    "                m.mul_(beta1).add_(g, alpha=1-beta1)\n",
    "                v.mul_(beta2).addcmul_(g, g, value=1-beta2)\n",
    "                dv = v - state['v_prev']\n",
    "                state['v_prev'].copy_(v)\n",
    "                f_min = (dv > 0).to(dtype=torch.int32)\n",
    "                f_max = (dv <= 0).to(dtype=torch.int32)\n",
    "                total_nonzero_fmin += count_nonzero(f_min)\n",
    "                total_nonzero_fmax += count_nonzero(f_max)\n",
    "                mhat = m / (1 - beta1 ** t)\n",
    "                state['step_dir'] = mhat / (v.sqrt().add(eps))\n",
    "        use_lr_min = (total_nonzero_fmax < total_nonzero_fmin) #\n",
    "        self.last_total_nonzero_fmin = total_nonzero_fmin\n",
    "        self.last_total_nonzero_fmax = total_nonzero_fmax\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr_min'] if use_lr_min else group['lr_max']\n",
    "            self.last_lr = lr\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None and 'step_dir' in self.state[p]:\n",
    "                    p.add_(self.state[p]['step_dir'], alpha=-lr)\n",
    "        return loss\n",
    "\n",
    "class ASGDAmsgrad(Optimizer):\n",
    "    \"\"\"ASGD-style optimizer mimicking AMSGrad\"\"\"\n",
    "    def __init__(self, params, lr=None, beta1=0.9, beta2=0.999, eps=1e-8,\n",
    "                 lr_min=1e-5, lr_max=3e-4):\n",
    "        defaults = dict(beta1=beta1, beta2=beta2, eps=eps, lr_min=lr_min, lr_max=lr_max)\n",
    "        super().__init__(params, defaults)\n",
    "        self.last_total_nonzero_fmin = 0\n",
    "        self.last_total_nonzero_fmax = 0\n",
    "        self.last_lr = lr_max\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        total_nonzero_fmin, total_nonzero_fmax = 0, 0\n",
    "        for group in self.param_groups:\n",
    "            beta1, beta2, eps = group['beta1'], group['beta2'], group['eps']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                g = p.grad\n",
    "                state = self.state[p]\n",
    "                if not state:\n",
    "                    state['t'] = 0\n",
    "                    state['m'] = torch.zeros_like(p)\n",
    "                    state['v'] = torch.zeros_like(p)\n",
    "                    state['v_hat'] = torch.zeros_like(p)\n",
    "                    state['v_prev'] = torch.zeros_like(p)\n",
    "                m, v, v_hat = state['m'], state['v'], state['v_hat']\n",
    "                state['t'] += 1\n",
    "                t = state['t']\n",
    "                m.mul_(beta1).add_(g, alpha=1-beta1)\n",
    "                v.mul_(beta2).addcmul_(g, g, value=1-beta2)\n",
    "                torch.maximum(v_hat, v, out=v_hat)\n",
    "                denom = v_hat.sqrt().add(eps)\n",
    "                dv = v - state['v_prev']\n",
    "                state['v_prev'].copy_(v)\n",
    "                f_min = (dv > 0).to(dtype=torch.int32)\n",
    "                f_max = (dv <= 0).to(dtype=torch.int32)\n",
    "                total_nonzero_fmin += count_nonzero(f_min)\n",
    "                total_nonzero_fmax += count_nonzero(f_max)\n",
    "                mhat = m / (1 - beta1 ** t)\n",
    "                state['step_dir'] = mhat / denom\n",
    "        use_lr_min = (total_nonzero_fmax <  total_nonzero_fmin) # \n",
    "        self.last_total_nonzero_fmin = total_nonzero_fmin\n",
    "        self.last_total_nonzero_fmax = total_nonzero_fmax\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr_min'] if use_lr_min else group['lr_max']\n",
    "            self.last_lr = lr\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None and 'step_dir' in self.state[p]:\n",
    "                    p.add_(self.state[p]['step_dir'], alpha=-lr)\n",
    "        return loss\n",
    "\n",
    "class Padam(Optimizer):\n",
    "    \"\"\"Padam optimizer\"\"\"\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9,0.999), eps=1e-8, weight_decay=0, amsgrad=False, p=0.125):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad, p=p)\n",
    "        super().__init__(params, defaults)\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None: continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Padam does not support sparse gradients')\n",
    "                state = self.state[p]\n",
    "                amsgrad = group['amsgrad']\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                    if amsgrad:\n",
    "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                if amsgrad:\n",
    "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1-beta1)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1-beta2)\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                if amsgrad:\n",
    "                    torch.maximum(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
    "                    denom = (max_exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
    "                else:\n",
    "                    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
    "                step_size = group['lr'] / bias_correction1\n",
    "                denom = denom.pow(group['p'])\n",
    "                if group['weight_decay'] != 0:\n",
    "                    grad = grad.add(p.data, alpha=group['weight_decay'])\n",
    "                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "# --------------------------\n",
    "# PPO Wrappers\n",
    "# --------------------------\n",
    "class PPOAdamAMSGrad(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": optim.Adam, \"optimizer_kwargs\": {\"amsgrad\": True}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOAdam(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": optim.Adam})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOSGD(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": optim.SGD})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOPadam(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": Padam, \"optimizer_kwargs\": {\"amsgrad\": True}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOASGDAdam(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": ASGDAdam, \"optimizer_kwargs\": {\"lr_min\":1e-7, \"lr_max\":1e-3}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PPOASGDAmsgrad(PPO):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if \"policy_kwargs\" not in kwargs: kwargs[\"policy_kwargs\"] = {}\n",
    "        kwargs[\"policy_kwargs\"].update({\"optimizer_class\": ASGDAmsgrad, \"optimizer_kwargs\": {\"lr_min\":1e-7, \"lr_max\":1e-3}})\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# -----------------------------\n",
    "# Training orchestration: train_compare_optimizers\n",
    "# -----------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "def train_and_evaluate_optimizers(modality_choice=\"all\",\n",
    "                                  expression_train=None, pseudotime_train=None,\n",
    "                                  expression_test=None, pseudotime_test=None,\n",
    "                                  modality_splits=None, gene_names=None,\n",
    "                                  adaptive_thresholds=None,\n",
    "                                  optimizers_to_run=None,\n",
    "                                  train_steps=10000,\n",
    "                                  save_dir=\"outputs\"):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    if optimizers_to_run is None:\n",
    "        optimizers_to_run = [\"adam\", \"amsgrad\"]\n",
    "\n",
    "    algo_map = {\n",
    "        \"sgd\": PPOSGD,\n",
    "        \"amsgrad\": PPOAdamAMSGrad,\n",
    "        \"adam\": PPOAdam,\n",
    "        \"padam\": PPOPadam,\n",
    "        \"asgdadam\": PPOASGDAdam,\n",
    "        \"asgdaamsgrad\": PPOASGDAmsgrad,\n",
    "    }\n",
    "\n",
    "    base_kwargs = {\n",
    "        \"gamma\": 0.99,\n",
    "        \"gae_lambda\": 0.95,\n",
    "        \"clip_range\": 0.2,\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"vf_coef\": 0.5,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"policy_kwargs\": dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])], activation_fn=nn.Tanh)\n",
    "    }\n",
    "\n",
    "    # -----------------------------\n",
    "    # Modality-specific data\n",
    "    # -----------------------------\n",
    "    if modality_choice == \"all\":\n",
    "        expr_train_mod = expression_train\n",
    "        expr_test_mod = expression_test\n",
    "        pseudo_train_mod = pseudotime_train[next(iter(pseudotime_train.keys()))]  # pick any modality's pseudotime\n",
    "        pseudo_test_mod = pseudotime_test[next(iter(pseudotime_test.keys()))]\n",
    "        gene_names_mod = gene_names\n",
    "        splits_for_env_mod = modality_splits\n",
    "    else:\n",
    "        start, end = modality_splits[modality_choice]\n",
    "        expr_train_mod = expression_train[:, start:end]\n",
    "        expr_test_mod = expression_test[:, start:end]\n",
    "        pseudo_train_mod = pseudotime_train[modality_choice]\n",
    "        pseudo_test_mod = pseudotime_test[modality_choice]\n",
    "        splits_for_env_mod = {modality_choice: (0, end - start)}\n",
    "        gene_names_mod = [f\"{modality_choice}_{i}\" for i in range(end - start)]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Environments\n",
    "    # -----------------------------\n",
    "    train_env = DummyVecEnv([make_env_factory(expr_train_mod, pseudo_train_mod, splits_for_env_mod, adaptive_thresholds)])\n",
    "    eval_env = DummyVecEnv([make_env_factory(expr_test_mod, pseudo_test_mod, splits_for_env_mod, adaptive_thresholds)])\n",
    "    eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
    "\n",
    "    trained_models = {}\n",
    "    results_reward = {}\n",
    "    train_metrics_df = []\n",
    "    test_metrics_df = []\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training loop\n",
    "    # -----------------------------\n",
    "    for opt_name in optimizers_to_run:\n",
    "        PPOClass = algo_map[opt_name]\n",
    "        print(f\"\\n--- Training {opt_name} on modality={modality_choice} ---\")\n",
    "\n",
    "        model = PPOClass(\"MlpPolicy\", train_env, verbose=1, seed=SEED, **base_kwargs)\n",
    "        model.learn(total_timesteps=train_steps)\n",
    "        trained_models[opt_name] = model\n",
    "\n",
    "        # Evaluate mean reward on test environment\n",
    "        mean_r, std_r = evaluate_model_sb3(model, eval_env, n_eval_episodes=N_EVAL_EPISODES)\n",
    "        results_reward[opt_name] = (mean_r, std_r)\n",
    "        print(f\"Eval mean reward ({opt_name}): {mean_r:.4f} Â± {std_r:.4f}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Per-gene evaluation on training data\n",
    "        # -----------------------------\n",
    "# -----------------------------\n",
    "# Per-gene evaluation on training data\n",
    "# -----------------------------\n",
    "# -----------------------------\n",
    "# Per-gene evaluation on training data\n",
    "# -----------------------------\n",
    "        df_train = evaluate_and_plot_multi_modality(\n",
    "            model=model,\n",
    "            algo_name=f\"{opt_name}_train\",\n",
    "            expression_test=expr_train_mod,\n",
    "            pseudotime_test=pseudo_train_mod,\n",
    "            modality_splits=splits_for_env_mod,  # pass the modality splits\n",
    "            gene_names=gene_names_mod,\n",
    "           # encoder_path=\"gcn_encoder.pth\",\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            n_episodes=30,\n",
    "            save_dir=PLOTS_DIR\n",
    "        )\n",
    "        train_metrics_df.append(df_train)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Per-gene evaluation on test data\n",
    "        # -----------------------------\n",
    "        df_test = evaluate_and_plot_multi_modality(\n",
    "            model=model,\n",
    "            algo_name=f\"{opt_name}_test\",\n",
    "            expression_test=expr_test_mod,\n",
    "            pseudotime_test=pseudo_test_mod,\n",
    "            modality_splits=splits_for_env_mod,\n",
    "            gene_names=gene_names_mod,\n",
    "          #  encoder_path=\"gcn_encoder.pth\",\n",
    "            adaptive_thresholds=adaptive_thresholds,\n",
    "            n_episodes=30,\n",
    "            save_dir=PLOTS_DIR\n",
    "        )\n",
    "        test_metrics_df.append(df_test)\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save training metrics\n",
    "    # -----------------------------\n",
    "    final_train_df = pd.concat(train_metrics_df, ignore_index=True)\n",
    "    final_train_df.to_csv(os.path.join(save_dir, f\"training_per_gene_metrics_{modality_choice}.csv\"), index=False)\n",
    "    train_summary_df = final_train_df.groupby(\"Algorithm\").mean(numeric_only=True)\n",
    "    train_summary_df.to_csv(os.path.join(save_dir, f\"training_overall_metrics_{modality_choice}.csv\"))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save testing metrics\n",
    "    # -----------------------------\n",
    "    final_test_df = pd.concat(test_metrics_df, ignore_index=True)\n",
    "    final_test_df.to_csv(os.path.join(save_dir, f\"testing_per_gene_metrics_{modality_choice}.csv\"), index=False)\n",
    "    test_summary_df = final_test_df.groupby(\"Algorithm\").mean(numeric_only=True)\n",
    "    test_summary_df.to_csv(os.path.join(save_dir, f\"testing_overall_metrics_{modality_choice}.csv\"))\n",
    "\n",
    "    print(f\"\\nâœ… Training & evaluation complete for all optimizers on modality={modality_choice}.\")\n",
    "\n",
    "    return trained_models, results_reward\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate a SB3 model\n",
    "# -----------------------------\n",
    "def evaluate_model_sb3(model, env, n_eval_episodes=10, deterministic=True):\n",
    "    \"\"\"\n",
    "    Evaluate a Stable-Baselines3 model.\n",
    "    \n",
    "    Returns:\n",
    "        mean_reward, std_reward\n",
    "    \"\"\"\n",
    "    all_rewards = []\n",
    "\n",
    "    for episode in range(n_eval_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0.0\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        all_rewards.append(total_reward)\n",
    "\n",
    "    mean_reward = np.mean(all_rewards)\n",
    "    std_reward = np.std(all_rewards)\n",
    "    return mean_reward, std_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46dc0c80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training sgd on modality=all ---\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 4803 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 3187          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1490589e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.4         |\n",
      "|    explained_variance   | 0.00596       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.92          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.000729     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 32.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2862          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 2             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5000318e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | 0.00461       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 21.6          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000491     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 26.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2716          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3471203e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | -0.00148      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.53          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000598     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 205           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2639          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8837629e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | -0.015        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 36            |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000757     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 22            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2600         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.144578e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 0.000256     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000547    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 305          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2572         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.662859e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -0.00434     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000561    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2546          |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4494464e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | 0.000655      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.42          |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.000644     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 33.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2529          |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0929612e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | -0.00419      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.68          |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000795     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 31.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2516          |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0768493e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | -5.61e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.64          |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.000842     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 39            |\n",
      "-------------------------------------------\n",
      "Eval mean reward (sgd): 0.6016 Â± 0.8036\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "\n",
      "--- Training adam on modality=all ---\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5139 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2711      |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0121074 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -11.3     |\n",
      "|    explained_variance   | 0.00596   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.61      |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -0.0141   |\n",
      "|    std                  | 0.988     |\n",
      "|    value_loss           | 28.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2346        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011277653 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2199        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011874599 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.00791    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.98        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2113        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015042812 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.0693      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2069        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426384 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2039        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016368875 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2017        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020964332 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.8         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2006       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01913354 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.37       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    std                  | 0.964      |\n",
      "|    value_loss           | 21         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1990        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021108087 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "Eval mean reward (adam): -0.3204 Â± 2.1633\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "\n",
      "--- Training amsgrad on modality=all ---\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5029 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2591        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012618834 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.00596     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.61        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2230        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011551775 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2101        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012323721 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.00565    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2021       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01605656 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.2      |\n",
      "|    explained_variance   | 0.0684     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.3       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 0.974      |\n",
      "|    value_loss           | 17.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1970        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015545026 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1934        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015292379 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.89        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1908        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021796584 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1886        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019561384 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1867        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019450778 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "Eval mean reward (amsgrad): -0.1583 Â± 2.1386\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "\n",
      "--- Training adam on modality=all ---\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 4986 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2582        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012618834 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.00596     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.61        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2231        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011551775 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2063        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012323721 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.00565    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1978       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01605656 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.2      |\n",
      "|    explained_variance   | 0.0684     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.3       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 0.974      |\n",
      "|    value_loss           | 17.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1934        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015545026 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1904        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015292379 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.89        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1885        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021796584 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1871        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019561384 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1860        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019450778 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "Eval mean reward (adam): -0.1958 Â± 2.1535\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "\n",
      "--- Training padam on modality=all ---\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5070 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2233          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.2905084e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.4         |\n",
      "|    explained_variance   | 0.00596       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.88          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 32            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1880          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3933734e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | 0.00498       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 21.8          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000966     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 26            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1743          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9325376e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | -0.00177      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.51          |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 203           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1671         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.769423e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -0.0145      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1630          |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1919324e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -11.3         |\n",
      "|    explained_variance   | 0.000533      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 15.6          |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 304           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1599         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.971099e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -0.000543    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1578        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.29158e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.00467     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1563         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.476917e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 0.000926     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1549         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.384352e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | 0.00227      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.59         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "Eval mean reward (padam): 0.5769 Â± 0.8367\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "\n",
      "--- Training asgdadam on modality=all ---\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5137 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2029       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01292507 |\n",
      "|    clip_fraction        | 0.0813     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.3      |\n",
      "|    explained_variance   | 0.00596    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.87       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00697   |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1687       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02469128 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.3      |\n",
      "|    explained_variance   | -0.00358   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00401   |\n",
      "|    std                  | 0.989      |\n",
      "|    value_loss           | 22         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1558        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029495478 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.000519    |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039746284 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.000554   |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1453        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031063471 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.0894      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.3         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1421        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041129336 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.91        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 7.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039500732 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 7.59        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1380      |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0539738 |\n",
      "|    clip_fraction        | 0.411     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -11.1     |\n",
      "|    explained_variance   | 0.658     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.06      |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -0.00371  |\n",
      "|    std                  | 0.972     |\n",
      "|    value_loss           | 10.6      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1367       |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05969589 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.598      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 0.969      |\n",
      "|    value_loss           | 5.68       |\n",
      "----------------------------------------\n",
      "Eval mean reward (asgdadam): -0.5174 Â± 2.4525\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "\n",
      "--- Training asgdaamsgrad on modality=all ---\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boabangfrancis/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5039 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1905        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012917681 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.00596     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.87        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1593       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02304923 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.3      |\n",
      "|    explained_variance   | -0.00357   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00273   |\n",
      "|    std                  | 0.988      |\n",
      "|    value_loss           | 22         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1473        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022810355 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.28        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1406       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03396616 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.2      |\n",
      "|    explained_variance   | 0.181      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00511   |\n",
      "|    std                  | 0.979      |\n",
      "|    value_loss           | 12.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1365        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030622736 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.0903      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1338       |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04261788 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 0.426      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.64       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 0.97       |\n",
      "|    value_loss           | 12.6       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1318      |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0455294 |\n",
      "|    clip_fraction        | 0.397     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -11.1     |\n",
      "|    explained_variance   | 0.591     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.752     |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.00202  |\n",
      "|    std                  | 0.972     |\n",
      "|    value_loss           | 7.97      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1304       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04159171 |\n",
      "|    clip_fraction        | 0.379      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 0.58       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.962      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043394197 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.853       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "Eval mean reward (asgdaamsgrad): -0.9281 Â± 2.3450\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "Evaluating modality: rna\n",
      "Evaluating modality: atac\n",
      "\n",
      "âœ… Training & evaluation complete for all optimizers on modality=all.\n"
     ]
    }
   ],
   "source": [
    "adaptive_thresholds = PerGeneAdaptiveThreshold(modality_dims)\n",
    "trained_models, rewards = train_and_evaluate_optimizers(\n",
    "    modality_choice=\"all\",  # or \"all\", \"atac\", \"adt\"\n",
    "    expression_train=fused_train,\n",
    "    pseudotime_train=pseudotime_train,\n",
    "    expression_test=fused_test,\n",
    "    pseudotime_test=pseudotime_test,\n",
    "    modality_splits=modality_splits,\n",
    "    gene_names=selected_gene_names,\n",
    "    adaptive_thresholds=adaptive_thresholds,\n",
    "    optimizers_to_run=[\"sgd\", \"adam\",\"amsgrad\",  \"adam\", \"padam\",\"asgdadam\",  \"asgdaamsgrad\"],\n",
    "    train_steps=20000,\n",
    "    save_dir=\"outputs\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb4436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336af73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c2472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
