{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b138818",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟡 Using CPU.\n",
      "=== Supervised training ImmuneNet ===\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Immune RL + PPO Distillation (Waddington Landscape)\n",
    "---------------------------------------------------\n",
    "- Gated + Adaptive-Threshold BioActivation (convex / nonconvex / twostage)\n",
    "- Dynamic Nonconvex Loss (Waddington landscape for critic stability)\n",
    "- Compares PPO modes on critic value metrics\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, csv, argparse, random, warnings, math\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "from copy import deepcopy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ============================================================\n",
    "# Torch setup\n",
    "# ============================================================\n",
    "HAS_TORCH = True\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset, DataLoader, Subset\n",
    "except Exception:\n",
    "    HAS_TORCH = False\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    if HAS_TORCH:\n",
    "        torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def get_device():\n",
    "    if not HAS_TORCH: return None\n",
    "    if torch.cuda.is_available():\n",
    "        d = torch.device(\"cuda\")\n",
    "        print(f\"🟢 Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "        return d\n",
    "    print(\"🟡 Using CPU.\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# Constants\n",
    "# ============================================================\n",
    "AA_VOCAB = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "AA_TO_ID = {a: i + 1 for i, a in enumerate(AA_VOCAB)}\n",
    "CYTOKINES = [\"NONE\", \"IL2\", \"IFNG\", \"IL10\", \"TNFA\"]\n",
    "CYTOKINE_TO_ID = {c: i for i, c in enumerate(CYTOKINES)}\n",
    "\n",
    "# ============================================================\n",
    "# Data utilities\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class Example:\n",
    "    peptide: str\n",
    "    allele: str\n",
    "    score: float\n",
    "    tcr: Optional[str] = None\n",
    "\n",
    "def smart_read_table(path: str) -> List[List[str]]:\n",
    "    rows = []\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        sample = f.read(2048); f.seek(0)\n",
    "        import csv as _csv\n",
    "        try: dialect = _csv.Sniffer().sniff(sample, delimiters=\"\\t,;\")\n",
    "        except Exception:\n",
    "            class dialect: delimiter = \",\"\n",
    "        reader = _csv.reader(f, dialect)\n",
    "        for row in reader:\n",
    "            if row: rows.append([c.strip() for c in row])\n",
    "    return rows\n",
    "\n",
    "def load_alleles(path: str) -> Dict[str, int]:\n",
    "    uniq = []\n",
    "    for r in smart_read_table(path):\n",
    "        for c in r:\n",
    "            for token in c.replace(\",\", \" \").split():\n",
    "                if token and token not in uniq:\n",
    "                    uniq.append(token)\n",
    "    return {a: i for i, a in enumerate(sorted(uniq))}\n",
    "\n",
    "def parse_examples(path: str, allele_to_id: Dict[str, int]) -> List[Example]:\n",
    "    rows = smart_read_table(path); exs = []\n",
    "    for r in rows:\n",
    "        if len(r) < 3: continue\n",
    "        pep, score_str, allele = r[0], r[1], r[2]\n",
    "        try: score = float(score_str)\n",
    "        except Exception: continue\n",
    "        if allele not in allele_to_id:\n",
    "            allele_to_id[allele] = len(allele_to_id)\n",
    "        exs.append(Example(peptide=pep, allele=allele, score=score))\n",
    "    return exs\n",
    "\n",
    "class SeqTokenizer:\n",
    "    def __init__(self, max_len=32): self.max_len=max_len\n",
    "    def encode(self, s: str):\n",
    "        ids = [AA_TO_ID.get(ch, 0) for ch in s[:self.max_len]]\n",
    "        if len(ids) < self.max_len: ids += [0]*(self.max_len - len(ids))\n",
    "        return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "class PeptideDataset(Dataset):\n",
    "    def __init__(self, exs, allele_to_id, pep_len=32, tcr_len=24):\n",
    "        self.exs = exs; self.allele_to_id = allele_to_id\n",
    "        self.tok_p = SeqTokenizer(pep_len); self.tok_t = SeqTokenizer(tcr_len)\n",
    "    def __len__(self): return len(self.exs)\n",
    "    def __getitem__(self, i):\n",
    "        e = self.exs[i]\n",
    "        pep = self.tok_p.encode(e.peptide)\n",
    "        tcr = self.tok_t.encode(e.tcr or \"CASSIRSSYEQYF\")\n",
    "        all_idx = self.allele_to_id.get(e.allele, 0)\n",
    "        return pep, tcr, all_idx, float(e.score)\n",
    "\n",
    "def collate_pep(batch):\n",
    "    pep, tcr, all_idx, y = zip(*batch)\n",
    "    pep = torch.stack(pep); tcr = torch.stack(tcr)\n",
    "    all_idx = torch.tensor(all_idx, dtype=torch.long)\n",
    "    y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "    cytok = torch.zeros((pep.size(0), len(CYTOKINES)), dtype=torch.float32)\n",
    "    cytok[:, CYTOKINE_TO_ID[\"NONE\"]] = 1.0\n",
    "    return pep, tcr, all_idx, cytok, y\n",
    "\n",
    "# ============================================================\n",
    "# Dynamic Nonconvex Loss (Waddington Landscape)\n",
    "# ============================================================\n",
    "def dynamic_nonconvex_loss(pred, target, epoch=0, eps=1e-6, freq=6.0, amp=0.3, basin_depth=0.2):\n",
    "    e = pred - target\n",
    "    base = torch.sqrt(torch.abs(e) + eps)\n",
    "    ripple = amp * torch.sin(freq * e) ** 2\n",
    "    basin = basin_depth * (e ** 4 - e ** 2)\n",
    "    decay = math.exp(-0.01 * epoch)\n",
    "    return torch.mean(base + decay * (ripple + basin))\n",
    "\n",
    "def regression_metrics(preds, targets):\n",
    "    preds = np.asarray(preds).flatten(); targets = np.asarray(targets).flatten()\n",
    "    mse = np.mean((preds - targets) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(preds - targets))\n",
    "    denom = np.sum((targets - np.mean(targets)) ** 2) + 1e-12\n",
    "    r2 = 1.0 - np.sum((targets - preds) ** 2) / denom\n",
    "    pear = pearsonr(preds, targets)[0] if len(preds) > 1 else 0.0\n",
    "    return {\"MSE\": float(mse), \"RMSE\": float(rmse), \"MAE\": float(mae), \"R2\": float(r2), \"Pearson\": float(pear)}\n",
    "\n",
    "# ============================================================\n",
    "# Gated + Adaptive Threshold BioActivation\n",
    "# ============================================================\n",
    "class BioActivation(nn.Module):\n",
    "    def __init__(self, dim=128, mode=\"nonconvex\", switch_epoch=5, adaptive=True):\n",
    "        super().__init__()\n",
    "        self.mode = mode; self.switch_epoch = switch_epoch; self._ep = 0\n",
    "        self.gate = nn.Linear(dim, dim)\n",
    "        if adaptive: self.threshold = nn.Parameter(torch.zeros(dim))\n",
    "        else: self.register_buffer(\"threshold\", torch.zeros(dim))\n",
    "    def set_epoch(self, ep:int): self._ep = ep\n",
    "    def forward(self, x):\n",
    "        g = torch.sigmoid(self.gate(x))\n",
    "        x_shift = x - self.threshold\n",
    "        if self.mode == \"convex\":\n",
    "            base = F.softplus(x_shift)\n",
    "        elif self.mode == \"nonconvex\":\n",
    "            base = x_shift * torch.sigmoid(x_shift)\n",
    "        elif self.mode == \"twostage\":\n",
    "            base = F.softplus(x_shift) if self._ep < self.switch_epoch else x_shift * torch.sigmoid(x_shift)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode {self.mode}\")\n",
    "        return base * g\n",
    "\n",
    "# ============================================================\n",
    "# ImmuneNet backbone\n",
    "# ============================================================\n",
    "class MiniGAT(nn.Module):\n",
    "    def __init__(self, vocab_size, dim, max_len=32, heads=4, layers=2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size+1, dim)\n",
    "        self.pos = nn.Embedding(max_len, dim)\n",
    "        enc = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=layers)\n",
    "        self.max_len = max_len\n",
    "    def forward(self, x):\n",
    "        L = min(x.size(1), self.max_len)\n",
    "        pos = torch.arange(L, device=x.device).unsqueeze(0).expand(x.size(0), L)\n",
    "        h = self.emb(x[:, :L]) + self.pos(pos)\n",
    "        h = self.encoder(h)\n",
    "        return torch.cat([h.mean(dim=1), h[:, 0, :]], dim=-1)\n",
    "\n",
    "class ImmuneNet(nn.Module):\n",
    "    def __init__(self, vocab_size, allele_count, dim=128, pep_len=32, tcr_len=24,\n",
    "                 act_mode=\"nonconvex\", switch_epoch=5):\n",
    "        super().__init__()\n",
    "        self.pep_enc = MiniGAT(vocab_size, dim, pep_len)\n",
    "        self.tcr_enc = MiniGAT(vocab_size, dim, tcr_len)\n",
    "        self.all_emb = nn.Embedding(allele_count+1, dim)\n",
    "        hid = 256; in_dim = 2*dim + 2*dim + dim\n",
    "        def act(): return BioActivation(dim=hid, mode=act_mode, switch_epoch=switch_epoch)\n",
    "        self.backbone = nn.Sequential(nn.Linear(in_dim, hid), act(), nn.Linear(hid, hid), act())\n",
    "        self.binding = nn.Linear(hid, 1)\n",
    "        self.recognition = nn.Linear(hid, 1)\n",
    "        self.cyt_fc = nn.Linear(len(CYTOKINES), 32)\n",
    "        self.response = nn.Sequential(nn.Linear(hid+32, 128), nn.ReLU(), nn.Linear(128, 1))\n",
    "    def encode_backbone(self, pep, tcr, all_idx):\n",
    "        pep_h = self.pep_enc(pep); tcr_h = self.tcr_enc(tcr); all_h = self.all_emb(all_idx)\n",
    "        return self.backbone(torch.cat([pep_h, tcr_h, all_h], dim=-1))\n",
    "    def forward(self, pep, tcr, all_idx, cytok):\n",
    "        z = self.encode_backbone(pep, tcr, all_idx)\n",
    "        bind = torch.sigmoid(self.binding(z)); recog = torch.sigmoid(self.recognition(z))\n",
    "        c = F.relu(self.cyt_fc(cytok)); resp = self.response(torch.cat([z, c], dim=-1))\n",
    "        return bind, recog, resp\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_metrics(model, loader, d):\n",
    "    model.eval(); preds, targets = [], []\n",
    "    for pep, tcr, all_idx, cytok, y in loader:\n",
    "        pep, tcr, all_idx, cytok = pep.to(d), tcr.to(d), all_idx.to(d), cytok.to(d)\n",
    "        bind, _, _ = model(pep, tcr, all_idx, cytok)\n",
    "        preds.extend(bind.cpu().numpy()); targets.extend(y.numpy())\n",
    "    return regression_metrics(preds, targets)\n",
    "\n",
    "def train_supervised(model, tr, val, d, epochs=3, lr=1e-3):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, BioActivation): m.set_epoch(ep)\n",
    "        model.train()\n",
    "        for pep,tcr,all_idx,cytok,y in tr:\n",
    "            pep,tcr,all_idx,cytok,y=[x.to(d) for x in (pep,tcr,all_idx,cytok,y)]\n",
    "            bind,_,_ = model(pep,tcr,all_idx,cytok)\n",
    "            loss = dynamic_nonconvex_loss(bind, y, epoch=ep)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        vm = eval_metrics(model, val, d)\n",
    "        print(f\"[ImmuneNet] Epoch {ep+1} | Val MSE={vm['MSE']:.5f}\")\n",
    "\n",
    "        \n",
    "# ============================================================\n",
    "# Adaptive Cytokine Environment (non-stationary drift)\n",
    "# ============================================================\n",
    "class AdaptiveCytokineEnv(nn.Module):\n",
    "    def __init__(self, num_cyt=len(CYTOKINES), rot_eps=0.02, base_bias=0.1, action_gain=0.25):\n",
    "        super().__init__()\n",
    "        self.num_cyt = num_cyt\n",
    "        self.rot_eps = rot_eps\n",
    "        self.base_bias = base_bias\n",
    "        self.action_gain = action_gain\n",
    "        self.register_buffer(\"R_t\", torch.eye(num_cyt))\n",
    "        self.register_buffer(\"b_t\", torch.zeros(num_cyt))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_epoch(self, ep:int):\n",
    "        # random re-orthogonalize rotation each epoch\n",
    "        M = torch.randn(self.num_cyt, self.num_cyt)\n",
    "        Q, R = torch.linalg.qr(M)\n",
    "        self.R_t = Q * torch.sign(torch.diag(R))\n",
    "        self.b_t = self.base_bias * torch.randn(self.num_cyt)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _drift(self):\n",
    "        Q, R = torch.linalg.qr(self.R_t + self.rot_eps * torch.randn_like(self.R_t))\n",
    "        self.R_t = Q * torch.sign(torch.diag(R))\n",
    "        self.b_t = 0.95 * self.b_t + 0.05 * torch.randn_like(self.b_t)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, model, pep, tcr, all_idx, a, z, d, cytok_prev=None):\n",
    "        B, N = pep.size(0), self.num_cyt\n",
    "        cytok = torch.zeros((B, N), device=d) if cytok_prev is None else cytok_prev.clone()\n",
    "        cytok[:, CYTOKINE_TO_ID[\"NONE\"]] = 1.0\n",
    "        a_rot = a @ self.R_t.to(d)\n",
    "        cytok_next = torch.clamp(cytok + self.action_gain * a_rot + self.b_t.to(d), 0.0, 1.0)\n",
    "        _, recog, resp = model(pep, tcr, all_idx, cytok_next)\n",
    "        reward = (0.7 * resp.squeeze(-1) + 0.3 * recog.squeeze(-1)).detach()\n",
    "        self._drift()\n",
    "        return reward, cytok_next\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PPO Policy (teacher/student)\n",
    "# ============================================================\n",
    "class PPOPolicy(nn.Module):\n",
    "    def __init__(self, input_dim, num_actions, width=256, depth=2,\n",
    "                 mode=\"nonconvex\", std=0.1, switch_epoch=3):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.switch_epoch = switch_epoch\n",
    "        self._ep = 0\n",
    "        self.relu = nn.ReLU(); self.swish = nn.SiLU()\n",
    "        self._std = std\n",
    "\n",
    "        def mlp(out_dim):\n",
    "            layers = []\n",
    "            d_in = input_dim\n",
    "            for _ in range(depth):\n",
    "                layers += [nn.Linear(d_in, width)]\n",
    "                d_in = width\n",
    "            layers.append(nn.Linear(d_in, out_dim))\n",
    "            return nn.ModuleList(layers)\n",
    "\n",
    "        self.actor_layers = mlp(num_actions)\n",
    "        self.critic_layers = mlp(1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight, gain=math.sqrt(2))\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def set_epoch(self, ep:int): self._ep = ep\n",
    "\n",
    "    def _apply_stack(self, layers, x):\n",
    "        for layer in layers[:-1]:\n",
    "            x = layer(x)\n",
    "            if self.mode == \"twostage\":\n",
    "                x = self.swish(x) if self._ep >= self.switch_epoch else self.relu(x)\n",
    "            elif self.mode == \"convex\":\n",
    "                x = self.relu(x)\n",
    "            else:\n",
    "                x = self.swish(x)\n",
    "        return layers[-1](x)\n",
    "\n",
    "    def actor_forward(self, x):  return self._apply_stack(self.actor_layers, x)\n",
    "    def critic_forward(self, x): return self._apply_stack(self.critic_layers, x)\n",
    "\n",
    "    def act(self, x):\n",
    "        mu = self.actor_forward(x)\n",
    "        dist = torch.distributions.Normal(mu, self._std)\n",
    "        u = dist.rsample()\n",
    "        a = torch.tanh(u)\n",
    "        logp = dist.log_prob(u).sum(-1) - torch.log(1 - a.pow(2) + 1e-6).sum(-1)\n",
    "        v = self.critic_forward(x).squeeze(-1)\n",
    "        return a, logp, v\n",
    "\n",
    "    def act_deterministic(self, x):\n",
    "        mu = self.actor_forward(x)\n",
    "        v = self.critic_forward(x).squeeze(-1)\n",
    "        return torch.tanh(mu), v\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PPO Teacher Training\n",
    "# ============================================================\n",
    "def ppo_train_multistep(policy, make_batch, env, immune_model, d,\n",
    "                        episodes=5, ppo_epochs=10, multistep_steps=5,\n",
    "                        gamma=0.99, clip=0.2, max_grad_norm=0.5, lr=5e-4):\n",
    "    opt = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "    ent_coef, vf_coef = 0.01, 0.5\n",
    "    for ep in range(episodes):\n",
    "        policy.set_epoch(ep); env.set_epoch(ep)\n",
    "        S,A,OL,Gt,Adv=[],[],[],[],[]\n",
    "        while True:\n",
    "            batch = make_batch()\n",
    "            if batch is None: break\n",
    "            z = batch[\"state\"].to(d)\n",
    "            pep,tcr,all_idx,cytok = [batch[k].to(d) for k in (\"pep\",\"tcr\",\"all\",\"cytok_init\")]\n",
    "            with torch.no_grad():\n",
    "                disc = torch.zeros(z.size(0), device=d)\n",
    "                cy = cytok\n",
    "                for t in range(multistep_steps):\n",
    "                    a, lp, v = policy.act(z)\n",
    "                    r, cy = env.step(immune_model, pep, tcr, all_idx, a, z, d, cy)\n",
    "                    disc += (gamma**t) * r\n",
    "                _, vL = policy.act_deterministic(z)\n",
    "                Aadv = (disc - vL).detach()\n",
    "            S.append(z); A.append(a); OL.append(lp); Gt.append(disc); Adv.append(Aadv)\n",
    "        if not S: continue\n",
    "        S,A,OL,Gt,Adv = map(torch.cat, (S,A,OL,Gt,Adv))\n",
    "        Adv = (Adv - Adv.mean()) / (Adv.std() + 1e-8)\n",
    "        for _ in range(ppo_epochs):\n",
    "            mu = policy.actor_forward(S)\n",
    "            dist = torch.distributions.Normal(mu, policy._std)\n",
    "            A_clamp = torch.clamp(A, -1 + 1e-6, 1 - 1e-6)\n",
    "            u = 0.5 * (torch.log1p(A_clamp) - torch.log1p(-A_clamp))\n",
    "            nlp = dist.log_prob(u).sum(-1) - torch.log(1 - A_clamp.pow(2) + 1e-6).sum(-1)\n",
    "            ratio = torch.exp(nlp - OL)\n",
    "            aloss = -torch.min(ratio*Adv, torch.clamp(ratio, 1-clip, 1+clip)*Adv).mean()\n",
    "            vpred = policy.critic_forward(S).squeeze(-1)\n",
    "            closs = dynamic_nonconvex_loss(vpred, Gt, epoch=ep)\n",
    "            entropy = dist.entropy().sum(-1).mean()\n",
    "            loss = aloss + vf_coef * closs - ent_coef * entropy\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            if max_grad_norm>0: torch.nn.utils.clip_grad_norm_(policy.parameters(), max_grad_norm)\n",
    "            opt.step()\n",
    "        print(f\"[PPO Teacher/{policy.mode}] Ep {ep+1}/{episodes} return={Gt.mean():.4f}\")\n",
    "    return policy\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PPO Distillation (Teacher → Student)\n",
    "# ============================================================\n",
    "def ppo_distill_loss(mu_s, mu_t, v_s, v_t, temp=1.0, alpha=0.7, std=0.1):\n",
    "    var = (std * temp) ** 2\n",
    "    kl = ((mu_s - mu_t) ** 2 / (2 * var)).mean()\n",
    "    v_mse = F.mse_loss(v_s, v_t)\n",
    "    return alpha * kl + (1 - alpha) * v_mse\n",
    "\n",
    "def ppo_distill(teacher, student, make_batch, d, epochs=3, lr=1e-4, temp=1.0, alpha=0.7):\n",
    "    teacher.eval()\n",
    "    opt = torch.optim.Adam(student.parameters(), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        student.set_epoch(ep)\n",
    "        total, nb = 0.0, 0\n",
    "        while True:\n",
    "            batch = make_batch()\n",
    "            if batch is None: break\n",
    "            z = batch[\"state\"].to(d)\n",
    "            with torch.no_grad():\n",
    "                mu_t = teacher.actor_forward(z)\n",
    "                _, v_t = teacher.act_deterministic(z)\n",
    "            mu_s = student.actor_forward(z)\n",
    "            _, v_s = student.act_deterministic(z)\n",
    "            loss = ppo_distill_loss(mu_s, mu_t, v_s, v_t, temp=temp, alpha=alpha, std=teacher._std)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total += loss.item(); nb += 1\n",
    "        print(f\"[PPO Distill/{teacher.mode}] Ep {ep+1}/{epochs} loss={total/max(nb,1):.6f}\")\n",
    "    return student\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Evaluation (Student critic vs Monte-Carlo)\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def evaluate_student_with_value_metrics(student, make_batch, env, immune_model, d,\n",
    "                                        episodes=2, multistep_steps=5, gamma=0.99):\n",
    "    v_list, G_list, returns = [], [], []\n",
    "    for ep in range(episodes):\n",
    "        student.set_epoch(ep); env.set_epoch(ep)\n",
    "        while True:\n",
    "            batch = make_batch()\n",
    "            if batch is None: break\n",
    "            z = batch[\"state\"].to(d)\n",
    "            pep,tcr,all_idx,cytok = [batch[k].to(d) for k in (\"pep\",\"tcr\",\"all\",\"cytok_init\")]\n",
    "            disc = torch.zeros(z.size(0), device=d); cy = cytok\n",
    "            for t in range(multistep_steps):\n",
    "                a, v = student.act_deterministic(z)\n",
    "                r, cy = env.step(immune_model, pep, tcr, all_idx, a, z, d, cy)\n",
    "                disc += (gamma**t) * r\n",
    "            _, v0 = student.act_deterministic(z)\n",
    "            v_list.append(v0.cpu().numpy()); G_list.append(disc.cpu().numpy())\n",
    "            returns.append(disc.mean().item())\n",
    "    if not v_list: \n",
    "        return 0.0, {\"MSE\":0,\"RMSE\":0,\"MAE\":0,\"R2\":0,\"Pearson\":0}\n",
    "    V = np.concatenate(v_list).ravel(); G = np.concatenate(G_list).ravel()\n",
    "    return np.mean(returns), regression_metrics(V, G)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main entry\n",
    "# ============================================================\n",
    "def main():\n",
    "    import sys\n",
    "    if any(a.startswith(\"-f\") for a in sys.argv): sys.argv=[sys.argv[0]]\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train\", default=\"train_BA1.txt\")\n",
    "    parser.add_argument(\"--test\", default=\"test_BA1.txt\")\n",
    "    parser.add_argument(\"--alleles\", default=\"allelelist.txt\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=2)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--switch_epoch\", type=int, default=1)\n",
    "    # PPO config\n",
    "    parser.add_argument(\"--ppo_multistep_steps\", type=int, default=5)\n",
    "    parser.add_argument(\"--ppo_gamma\", type=float, default=0.99)\n",
    "    parser.add_argument(\"--ppo_clip\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--ppo_std\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--ppo_teacher_width\", type=int, default=512)\n",
    "    parser.add_argument(\"--ppo_teacher_depth\", type=int, default=4)\n",
    "    parser.add_argument(\"--ppo_teacher_episodes\", type=int, default=2)\n",
    "    parser.add_argument(\"--ppo_teacher_epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--ppo_teacher_lr\", type=float, default=5e-4)\n",
    "    parser.add_argument(\"--ppo_student_width\", type=int, default=128)\n",
    "    parser.add_argument(\"--ppo_student_depth\", type=int, default=2)\n",
    "    parser.add_argument(\"--ppo_distill_epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--ppo_distill_lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--ppo_distill_temp\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--ppo_distill_alpha\", type=float, default=0.7)\n",
    "    parser.add_argument(\"--modes\", type=str, default=\"convex, nonconvex, twostage\") #\n",
    "    args,_ = parser.parse_known_args()\n",
    "\n",
    "    d = get_device(); seed_everything(1)\n",
    "    if not HAS_TORCH: return print(\"❌ PyTorch missing\")\n",
    "\n",
    "    allele_to_id = load_alleles(args.alleles)\n",
    "    tr = parse_examples(args.train, allele_to_id)\n",
    "    ts = parse_examples(args.test, allele_to_id)\n",
    "\n",
    "    tr_ds = PeptideDataset(tr, allele_to_id); ts_ds = PeptideDataset(ts, allele_to_id)\n",
    "    N=len(tr_ds); idx=list(range(N)); random.shuffle(idx)\n",
    "    val=max(1,int(0.2*N))\n",
    "    tr_dl=DataLoader(Subset(tr_ds,idx[val:]),batch_size=args.batch_size,shuffle=True,collate_fn=collate_pep)\n",
    "    val_dl=DataLoader(Subset(tr_ds,idx[:val]),batch_size=args.batch_size,shuffle=False,collate_fn=collate_pep)\n",
    "    ts_dl=DataLoader(ts_ds,batch_size=args.batch_size,shuffle=False,collate_fn=collate_pep)\n",
    "\n",
    "    # Train ImmuneNet (frozen for PPO)\n",
    "    immune=ImmuneNet(len(AA_VOCAB),len(allele_to_id),act_mode=\"twostage\",\n",
    "                     switch_epoch=args.switch_epoch).to(d)\n",
    "    print(\"=== Supervised training ImmuneNet ===\")\n",
    "    train_supervised(immune,tr_dl,val_dl,d,epochs=args.epochs)\n",
    "    print(\"Test metrics:\",eval_metrics(immune,ts_dl,d))\n",
    "\n",
    "    # Batch builder\n",
    "    def make_batch_gen():\n",
    "        def make_batch():\n",
    "            if not hasattr(make_batch,\"it\"): make_batch.it=iter(tr_dl)\n",
    "            try: pep,tcr,all_idx,cytok,y=next(make_batch.it)\n",
    "            except StopIteration:\n",
    "                make_batch.it=iter(tr_dl); return None\n",
    "            with torch.no_grad():\n",
    "                z=immune.encode_backbone(pep.to(d),tcr.to(d),all_idx.to(d)).detach()\n",
    "            return {\"state\":z,\"pep\":pep,\"tcr\":tcr,\"all\":all_idx,\"cytok_init\":cytok}\n",
    "        return make_batch\n",
    "\n",
    "    results=[]\n",
    "    for mode in [m.strip() for m in args.modes.split(\",\") if m.strip()]:\n",
    "        print(f\"\\n===== Mode {mode.upper()} =====\")\n",
    "        env=AdaptiveCytokineEnv().to(d)\n",
    "        teacher=PPOPolicy(256,len(CYTOKINES),args.ppo_teacher_width,args.ppo_teacher_depth,\n",
    "                          mode,args.ppo_std,args.switch_epoch).to(d)\n",
    "        make_batch=make_batch_gen()\n",
    "        teacher=ppo_train_multistep(teacher,make_batch,env,immune,d,\n",
    "                                    args.ppo_teacher_episodes,args.ppo_teacher_epochs,\n",
    "                                    args.ppo_multistep_steps,args.ppo_gamma,\n",
    "                                    args.ppo_clip,lr=args.ppo_teacher_lr)\n",
    "\n",
    "        student=PPOPolicy(256,len(CYTOKINES),args.ppo_student_width,args.ppo_student_depth,\n",
    "                          mode,args.ppo_std,args.switch_epoch).to(d)\n",
    "        make_batch=make_batch_gen()\n",
    "        student=ppo_distill(teacher,student,make_batch,d,args.ppo_distill_epochs,\n",
    "                            args.ppo_distill_lr,args.ppo_distill_temp,args.ppo_distill_alpha)\n",
    "\n",
    "        make_batch=make_batch_gen()\n",
    "        mean_ret,metrics=evaluate_student_with_value_metrics(student,make_batch,env,immune,d,\n",
    "                                                             2,args.ppo_multistep_steps,args.ppo_gamma)\n",
    "        print(\n",
    "          f\"[Eval/{mode}] Return={mean_ret:.4f} | \"\n",
    "          f\"MSE={metrics['MSE']:.4f} | RMSE={metrics['RMSE']:.4f} | \"\n",
    "          f\"MAE={metrics['MAE']:.4f} | R2={metrics['R2']:.3f} | \"\n",
    "          f\"Pearson={metrics['Pearson']:.3f}\"\n",
    "        )\n",
    "        torch.save(student.state_dict(),f\"ppo_student_{mode}.pt\")\n",
    "        results.append([mode,mean_ret,metrics[\"MSE\"],metrics[\"RMSE\"],metrics[\"MAE\"],\n",
    "                        metrics[\"R2\"],metrics[\"Pearson\"]])\n",
    "\n",
    "    with open(\"ppo_distilled_comparison.csv\",\"w\",newline=\"\") as f:\n",
    "        w=csv.writer(f); w.writerow([\"Mode\",\"Return\",\"MSE\",\"RMSE\",\"MAE\",\"R2\",\"Pearson\"]); w.writerows(results)\n",
    "    print(\"✅ Saved ppo_distilled_comparison.csv\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    try: main()\n",
    "    except SystemExit: pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5a3a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ba356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b0e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
